import os
import io
import re
from typing import Tuple

import streamlit as st
from dotenv import load_dotenv
from docx import Document

# æ¡ä»¶å¯¼å…¥ï¼ˆOCR ç›¸å…³åº“åœ¨äº‘ç«¯ä¸ä¸€å®šå¯ç”¨ï¼‰
try:
    import pdfplumber
except Exception:
    pdfplumber = None

# OCR ä¾èµ–ï¼šå¯èƒ½åœ¨äº‘ç«¯ä¸å¯ç”¨ï¼Œè¿è¡Œæ—¶åšæ£€æµ‹
def _safe_import_ocr():
    try:
        import pytesseract  # type: ignore
        from pdf2image import convert_from_bytes  # type: ignore
        return pytesseract, convert_from_bytes
    except Exception:
        return None, None

from openai import OpenAI

# ========= é¡µé¢é…ç½® & æ ·å¼ä¿®å¤ =========
st.set_page_config(page_title="AI æ™ºèƒ½ç®€å†ä¼˜åŒ–", page_icon="ğŸ§ ", layout="wide")
st.markdown("""
<style>
/* ä¿®å¤æ ‡é¢˜è¢«é®æŒ¡ï¼šä¿ç•™ Header é«˜åº¦ï¼Œç»™å†…å®¹åŠ ä¸Šå†…è¾¹è· */
[data-testid="stHeader"]{visibility:visible;height:2.8rem;background:transparent;}
[data-testid="stToolbar"]{visibility:hidden;height:2.8rem;}
.block-container{padding-top:3.2rem!important;max-width:1200px;}
h1:first-child,.stMarkdown h1:first-child{margin-top:0.6rem!important;}
/* è®©æç¤ºã€æŒ‰é’®æ›´é†’ç›®ä¸€äº› */
button[kind="primary"] { font-weight: 600; }
</style>
""", unsafe_allow_html=True)

# ========= è½½å…¥ OpenAI =========
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
if not OPENAI_API_KEY:
    st.error("âš ï¸ æœªæ£€æµ‹åˆ° OPENAI_API_KEYã€‚è¯·åœ¨ Streamlit â†’ Settings â†’ Secrets æ·»åŠ ï¼š\nOPENAI_API_KEY = \"sk-xxxx\"")
client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

# ========= å·¥å…·å‡½æ•° =========
def detect_language(text: str) -> str:
    """ç®€å•æ£€æµ‹ï¼šä¸­æ–‡å¤šåˆ™ zhï¼Œå¦åˆ™ en"""
    zh = len(re.findall(r'[\u4e00-\u9fff]', text))
    en = len(re.findall(r'[A-Za-z]', text))
    return "zh" if zh > en else "en"

def _read_pdf_text(file_bytes: bytes) -> str:
    """ä¼˜å…ˆä½¿ç”¨ pdfplumber æå–æ–‡æœ¬"""
    if not pdfplumber:
        return ""
    text = ""
    with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
        for p in pdf.pages:
            text += (p.extract_text() or "") + "\n"
    return text.strip()

def _ocr_pdf(file_bytes: bytes) -> str:
    """ç”¨ OCR ä»æ‰«æ PDF ä¸­è¯†åˆ«æ–‡æœ¬ï¼ˆè‹¥è¿è¡Œç¯å¢ƒç¼ºåº“åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²ï¼‰"""
    pytesseract, convert_from_bytes = _safe_import_ocr()
    if not (pytesseract and convert_from_bytes):
        return ""
    try:
        images = convert_from_bytes(file_bytes, dpi=300)
        parts = []
        for im in images:
            parts.append(pytesseract.image_to_string(im, lang="chi_sim+eng"))
        return "\n".join(parts).strip()
    except Exception:
        return ""

def read_resume(uploaded_file, use_ocr: bool) -> Tuple[str, str]:
    """
    è¯»å– PDF/DOCX/TXTï¼›è¿”å› (æ–‡æœ¬, æ ¼å¼å)
    - è‹¥ä¸º PDF ä¸”æ–‡æœ¬æå°‘ï¼Œä¸”å¼€å¯ OCRï¼Œåˆ™å°è¯• OCRã€‚
    """
    name = uploaded_file.name.lower()
    raw = uploaded_file.read()
    uploaded_file.seek(0)

    if name.endswith(".pdf"):
        text = _read_pdf_text(raw)
        # åˆ¤å®šæ˜¯å¦æ‰«æä»¶ï¼ˆæ–‡æœ¬æå°‘ï¼‰
        if use_ocr and len(text) < 50:
            ocr_text = _ocr_pdf(raw)
            if ocr_text:
                return ocr_text, "PDF(OCR)"
            else:
                # OCR ä¸å¯ç”¨æˆ–å¤±è´¥
                return text or "", "PDF"
        return text, "PDF"

    elif name.endswith(".docx"):
        doc = Document(io.BytesIO(raw))
        return "\n".join(p.text for p in doc.paragraphs).strip(), "DOCX"

    elif name.endswith(".txt"):
        try:
            return raw.decode("utf-8").strip(), "TXT"
        except Exception:
            return raw.decode("latin-1", errors="ignore").strip(), "TXT"

    else:
        raise ValueError("ä»…æ”¯æŒ PDF / DOCX / TXT")

def build_focus_instructions(focus_tags, custom_points, lang):
    """æ ¹æ®ä¾§æ çš„ç²¾ä¿®ä¾§é‡ã€å¢å¼ºç‚¹ï¼Œç”Ÿæˆä¼˜åŒ–æŒ‡ä»¤ç‰‡æ®µï¼ˆä¸­/è‹±ï¼‰"""
    if not focus_tags and not custom_points:
        return ""
    if lang == "zh":
        parts = []
        if focus_tags:
            parts.append("è¯·åœ¨ä¼˜åŒ–ä¸­ç‰¹åˆ«å¼ºè°ƒä»¥ä¸‹ä¾§é‡ç‚¹ï¼š" + "ã€".join(focus_tags) + "ã€‚")
        if custom_points:
            parts.append("å…¶ä»–è‡ªå®šä¹‰è¦æ±‚ï¼š" + custom_points.strip())
        return "\n".join(parts)
    else:
        parts = []
        if focus_tags:
            parts.append("Please emphasise the following focus areas in the optimisation: " +
                         ", ".join(focus_tags) + ".")
    if custom_points:
        parts.append("Additional user notes: " + custom_points.strip())
    return "\n".join(parts)

def llm_optimize_resume(resume_text: str, jd_text: str, lang: str, focus_directives: str) -> str:
    """è°ƒç”¨æ¨¡å‹ç”Ÿæˆä¼˜åŒ–ç®€å†"""
    if not client:
        raise RuntimeError("OpenAI client æœªåˆå§‹åŒ–ã€‚è¯·é…ç½® OPENAI_API_KEYã€‚")
    prompt = f"""
You are a professional career consultant AI.
Optimise the following resume to better match the job description / user instructions.
Keep the same language as the resume: {"Chinese (ç®€ä½“ä¸­æ–‡)" if lang=="zh" else "English"}.
Focus on quantifiable achievements, clear structure, strong action verbs, ATS-friendly formatting.

[Job description or user instructions]
{jd_text or "(none)"}

[User focus directives]
{focus_directives or "(none)"}

[Original resume]
{resume_text}

[Output requirement]
Return ONLY the optimised resume text (no extra commentary).
"""
    rsp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role":"user","content":prompt}],
        temperature=0.6,
    )
    return (rsp.choices[0].message.content or "").strip()

def llm_cover_letter(resume_text: str, jd_text: str, lang: str, focus_directives: str) -> str:
    """è°ƒç”¨æ¨¡å‹ç”Ÿæˆæ±‚èŒä¿¡"""
    if not client:
        raise RuntimeError("OpenAI client æœªåˆå§‹åŒ–ã€‚è¯·é…ç½® OPENAI_API_KEYã€‚")
    prompt = f"""
Write a concise, compelling cover letter in {"Chinese (ç®€ä½“ä¸­æ–‡)" if lang=="zh" else "English"}.
Match the resume's background and the job needs.

[Job description or user instructions]
{jd_text or "(none)"}

[User focus directives]
{focus_directives or "(none)"}

[Resume]
{resume_text}

[Output requirement]
Return ONLY the cover letter body (no extra notes).
"""
    rsp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role":"user","content":prompt}],
        temperature=0.6,
    )
    return (rsp.choices[0].message.content or "").strip()

def to_docx_bytes(text: str) -> bytes:
    """å°†çº¯æ–‡æœ¬å¯¼å‡ºä¸º .docx"""
    doc = Document()
    for line in (text or "").split("\n"):
        doc.add_paragraph(line)
    buf = io.BytesIO()
    doc.save(buf)
    buf.seek(0)
    return buf.getvalue()

# ========= SessionStateï¼ˆä¸‹è½½ä¸ä¸¢ï¼‰ =========
for k, v in {
    "optimized_resume": None,
    "cover_letter": None,
    "detected_lang": None,
    "last_file_format": None,
}.items():
    if k not in st.session_state:
        st.session_state[k] = v

# ========= å·¦ä¾§æ ï¼šç”¨æˆ·é€‰é¡¹ =========
st.sidebar.header("è®¾ç½®")
st.sidebar.caption("ä»¥ä¸‹é€‰é¡¹ä»…å½±å“ç”Ÿæˆç­–ç•¥")

# ç²¾ä¿®ä¾§é‡ï¼ˆå¤šé€‰ï¼‰
FOCUS_OPTIONS = ["ä¸šåŠ¡å½±å“", "é‡åŒ–æˆæœ", "é¡¹ç›®ç®¡ç†", "æ²Ÿé€šåä½œ", "é¢†å¯¼åŠ›", "æŠ€æœ¯æ·±åº¦", "AI/æ•°æ®åˆ†æ", "ç ”ç©¶èƒ½åŠ›", "å®¢æˆ·ä»·å€¼"]
focus_tags = st.sidebar.multiselect("ç²¾ä¿®ä¾§é‡ï¼ˆå¯å¤šé€‰ï¼‰", FOCUS_OPTIONS, default=["ä¸šåŠ¡å½±å“", "é‡åŒ–æˆæœ"])

# å¢å¼ºç‚¹ï¼ˆè‡ªå®šä¹‰ï¼‰
custom_points = st.sidebar.text_area("å¢å¼ºç‚¹ï¼ˆå¯è‡ªå®šä¹‰ï¼‰", placeholder="ä¾‹å¦‚ï¼šçªå‡ºXè¡Œä¸šç»éªŒï¼›é‡åŒ–æ¯æ®µæˆæœï¼›å¼ºè°ƒè·¨å›¢é˜Ÿåä½œâ€¦", height=90)

# ç”Ÿæˆæ±‚èŒä¿¡
need_cl = st.sidebar.checkbox("ç”Ÿæˆæ±‚èŒä¿¡ï¼ˆCover Letterï¼‰", value=True)

# å¯ç”¨ OCRï¼ˆæ‰«æPDFï¼‰
use_ocr = st.sidebar.checkbox("å¯ç”¨ OCRï¼ˆæ‰«æ PDFï¼‰", value=False,
                              help="è‹¥ PDF æ˜¯æ‰«æä»¶ï¼Œå¼€å¯åå°è¯• OCR è¯†åˆ«ã€‚äº‘ç«¯è‹¥ç¼ºå°‘ Tesseract/Poppler å°†è‡ªåŠ¨é™çº§å¹¶æç¤ºã€‚")

st.title("ğŸ§  AI æ™ºèƒ½ç®€å†ä¼˜åŒ–")
st.caption("ä¸Šä¼ ç®€å†ï¼ŒAI å°†æ ¹æ® JD/æŒ‡ä»¤ä¸€é”®ä¼˜åŒ–ï¼›å¯é€‰ç”Ÿæˆæ±‚èŒä¿¡ï¼ˆCover Letterï¼Œè¯­è¨€è‡ªåŠ¨éšç®€å†ï¼‰ã€‚")

# å³ä¾§ä¸»ä½“
col_left, col_right = st.columns([1, 1])

with col_left:
    uploaded_file = st.file_uploader("ä¸Šä¼ ç®€å†ï¼ˆPDF / DOCX / TXTï¼‰", type=["pdf","docx","txt"], label_visibility="visible")

with col_right:
    jd_text = st.text_area(
        "ç²˜è´´ç›®æ ‡èŒä½ JD æˆ–ä¼˜åŒ–æŒ‡ä»¤ï¼ˆå¯æ‰¹é‡ã€ç”¨åˆ†éš”ï¼‰",
        placeholder="ä¾‹å¦‚ï¼šActuarial graduate role at Deloitte. è¯·é‡ç‚¹çªå‡ºæ•°æ®åˆ†æä¸å»ºæ¨¡èƒ½åŠ›ï¼›Cover Letter æ›´æ­£å¼ã€‚",
        height=150
    )

st.info("ğŸ’¡ æç¤ºï¼šå¯åœ¨å·¦ä¾§è®¾ç½®â€œç²¾ä¿®ä¾§é‡/å¢å¼ºç‚¹â€ï¼›è‹¥ PDF ä¸ºæ‰«æä»¶ï¼Œå¯å¼€å¯ OCRã€‚", icon="ğŸ’¡")

# ä½¿ç”¨ form è®©æŒ‰é’®å§‹ç»ˆå¯è§
with st.form("gen_form", clear_on_submit=False):
    submitted = st.form_submit_button("ğŸš€ ä¸€é”®ç”Ÿæˆ", use_container_width=True)

if submitted:
    if not uploaded_file:
        st.warning("è¯·å…ˆä¸Šä¼ ç®€å†æ–‡ä»¶ï¼ˆPDF / DOCX / TXTï¼‰ã€‚")
    elif not OPENAI_API_KEY:
        st.error("æœªé…ç½® OPENAI_API_KEYï¼Œæ— æ³•è°ƒç”¨æ¨¡å‹ã€‚")
    else:
        try:
            with st.spinner("AI æ­£åœ¨åˆ†æå¹¶ä¼˜åŒ–ä¸­ï¼Œè¯·ç¨å€™â€¦"):
                resume_text, fmt = read_resume(uploaded_file, use_ocr=use_ocr)
                if not resume_text:
                    st.error("æœªèƒ½ä»ç®€å†ä¸­è§£æå‡ºæ–‡æœ¬ã€‚è‹¥ä¸ºæ‰«æ PDFï¼Œè¯·å°è¯•å‹¾é€‰â€œå¯ç”¨ OCRâ€ã€‚")
                else:
                    lang = detect_language(resume_text)
                    st.session_state.detected_lang = lang
                    st.session_state.last_file_format = fmt

                    focus_directives = build_focus_instructions(focus_tags, custom_points, lang)

                    optimized = llm_optimize_resume(resume_text, jd_text, lang, focus_directives)
                    st.session_state.optimized_resume = optimized

                    if need_cl:
                        cl = llm_cover_letter(resume_text, jd_text, lang, focus_directives)
                        st.session_state.cover_letter = cl
                    else:
                        st.session_state.cover_letter = None

            if st.session_state.optimized_resume:
                lang_badge = "ä¸­æ–‡" if st.session_state.detected_lang == "zh" else "English"
                st.success(f"å·²å®Œæˆï¼æ£€æµ‹è¯­è¨€ï¼š**{lang_badge}**ï¼Œæ¥æºï¼š**{st.session_state.last_file_format}**ã€‚è¯·åœ¨ä¸‹æ–¹æŸ¥çœ‹ä¸ä¸‹è½½ã€‚")

                if use_ocr and st.session_state.last_file_format == "PDF" and pdfplumber and len(st.session_state.optimized_resume) < 50:
                    st.warning("çœ‹èµ·æ¥ PDF å¯èƒ½æ˜¯æ‰«æä»¶ï¼Œä¸” OCR æœªå¯ç”¨æˆ–æœªè¯†åˆ«åˆ°æ–‡æœ¬ã€‚è‹¥åœ¨äº‘ç«¯ï¼Œè¯·ç¡®è®¤ Poppler / Tesseract ä¾èµ–ã€‚")

        except Exception as e:
            st.error(f"âŒ å‡ºé”™ï¼š{e}")

# ======= ç»“æœå±•ç¤º/ä¸‹è½½ï¼ˆä¿æŒåœ¨é¡µé¢ä¸Šï¼Œä¸ä¼šå› ä¸‹è½½è€Œæ¶ˆå¤±ï¼‰ =======
if st.session_state.optimized_resume:
    st.subheader("âœ… ä¼˜åŒ–åçš„ç®€å†")
    st.text_area("Resume Preview", st.session_state.optimized_resume, height=360)
    st.download_button(
        "ğŸ“„ ä¸‹è½½ä¼˜åŒ–ç®€å†ï¼ˆWordï¼‰",
        data=to_docx_bytes(st.session_state.optimized_resume),
        file_name="Optimized_Resume.docx",
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        use_container_width=True
    )

if st.session_state.cover_letter:
    st.subheader("ğŸ“¬ æ±‚èŒä¿¡ï¼ˆCover Letterï¼‰")
    st.text_area("Cover Letter Preview", st.session_state.cover_letter, height=280)
    st.download_button(
        "ğŸ“„ ä¸‹è½½æ±‚èŒä¿¡ï¼ˆWordï¼‰",
        data=to_docx_bytes(st.session_state.cover_letter),
        file_name="Cover_Letter.docx",
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        use_container_width=True
    )

st.markdown("---")
st.caption("Â© 2025 AI Resume Optimizerï½œä»…ä¾›ä¸ªäººæ±‚èŒä½¿ç”¨ï¼Œç¦æ­¢å•†ç”¨ä¸çˆ¬å–ã€‚")