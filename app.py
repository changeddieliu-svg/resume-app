# app.py
# AI æ™ºèƒ½ç®€å†ä¼˜åŒ–ï¼ˆè‡ªåŠ¨è¯†åˆ«ä¸­/è‹±æ–‡ -> åŒè¯­ç§è¾“å‡ºï¼›å¯ç”Ÿæˆ Cover Letterï¼›ä¸‹è½½åä¸ä¸¢ç»“æœï¼›å¢å¼ºç‚¹å¯è¾“å…¥ï¼‰
# è½»ä¾èµ–ï¼šé»˜è®¤ç”¨ pdfplumber / python-docxï¼›OCR ä¸ PDF å¯¼å‡ºä¸ºå¯é€‰èƒ½åŠ›ï¼ˆä¸å®‰è£…ä¹Ÿèƒ½è·‘ï¼‰

import os
import io
import re
from typing import Optional, Tuple

import streamlit as st

# ---------- dotenvï¼ˆå¯é€‰ï¼‰ï¼Œä¼˜å…ˆç”¨ Streamlit Secrets ----------
try:
    from dotenv import load_dotenv
    load_dotenv()
except Exception:
    pass

# ---------- æ–‡æ¡£è§£æ ----------
import pdfplumber
from docx import Document

# ---------- OCRï¼ˆå¯é€‰ï¼‰ ----------
_HAS_OCR = True
try:
    from pdf2image import convert_from_bytes
    import pytesseract
    from PIL import Image  # noqa
except Exception:
    _HAS_OCR = False

# ---------- PDF å¯¼å‡ºï¼ˆå¯é€‰ï¼‰ ----------
_HAS_PDF = True
try:
    from reportlab.pdfgen import canvas
    from reportlab.lib.pagesizes import A4
    from reportlab.lib.units import mm
except Exception:
    _HAS_PDF = False

# ---------- OpenAI SDK ----------
from openai import OpenAI

# =================== é¡µé¢é…ç½® & è½»é‡é˜²æ‹· ===================
st.set_page_config(page_title="AI æ™ºèƒ½ç®€å†ä¼˜åŒ–", page_icon="ğŸ§ ", layout="wide")
st.markdown("""
<style>
/* å¯é€‰ï¼šéšè—å³ä¸Šè§’å·¥å…·æ¡/å·¦ä¸Šè§’èœå•/åº•éƒ¨æ°´å°ï¼ˆéœ€è¦çš„è¯ä¿ç•™ï¼‰*/
[data-testid="stToolbar"] {visibility: hidden; height: 0;}
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
.block-container {padding-top: 1rem;}
</style>
<script>
// æ§åˆ¶å°æç¤ºï¼ˆä¸å½±å“åŠŸèƒ½ï¼‰
console.log("%cè­¦å‘Š WARNING","color:#fff;background:#d32f2f;padding:6px 10px;border-radius:4px;font-weight:700;font-size:14px");
console.log("%cæœ¬åº”ç”¨ä¸å…¶æç¤ºè¯/æ¨¡æ¿å—ç‰ˆæƒä¿æŠ¤ã€‚ä»…ä¾›ä¸ªäººæ±‚èŒä½¿ç”¨ï¼Œç¦æ­¢æœªæˆæƒå¤åˆ¶ã€çˆ¬å–æˆ–å•†ç”¨ã€‚","color:#d32f2f;font-size:12px");
// é™ä½éšæ‰‹å¤åˆ¶çš„ä¾¿åˆ©åº¦ï¼ˆå¯åˆ ï¼‰
document.addEventListener("contextmenu", e => e.preventDefault());
</script>
""", unsafe_allow_html=True)

# =================== OpenAI å®¢æˆ·ç«¯ ===================
def get_openai_client() -> OpenAI:
    api_key = st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY", ""))
    if not api_key:
        st.error("æœªæ£€æµ‹åˆ° OPENAI_API_KEYï¼Œè¯·åœ¨ Streamlit Secrets æˆ– .env ä¸­é…ç½®ã€‚")
        st.stop()
    return OpenAI(api_key=api_key)

def get_model_name() -> str:
    return st.secrets.get("MODEL_NAME", os.getenv("MODEL_NAME", "gpt-4o-mini"))

# =================== è¯­è¨€æ£€æµ‹ï¼ˆEN/ZHï¼‰ ===================
try:
    from langdetect import detect as _langdetect
    _HAS_LANGDETECT = True
except Exception:
    _HAS_LANGDETECT = False

_ZH_HINTS = ["æ•™è‚²","é¡¹ç›®","å·¥ä½œç»å†","ä¸ªäººä¿¡æ¯","æŠ€èƒ½","èŒè´£","æˆå°±","æˆæœ","æ€§åˆ«","å‡ºç”Ÿ","åœ°å€","ç”µè¯","é‚®ç®±"]
_EN_HINTS = ["Education","Experience","Project","Work","Skills","Summary","Achievements","Responsibilities","Email","Phone","Address"]

def _ratio_non_ascii(text: str) -> float:
    if not text:
        return 0.0
    non_ascii = sum(1 for ch in text if ord(ch) > 127)
    return non_ascii / max(1, len(text))

def _contains_any(text: str, words) -> bool:
    t = text[:2000]
    return any(w in t for w in words)

def detect_lang_en_zh(text: str) -> str:
    """
    è¿”å› 'en' æˆ– 'zh'ã€‚é¡ºåºï¼šlangdetect â†’ éASCIIæ¯”ä¾‹ â†’ å…³é”®è¯å¯å‘ â†’ é»˜è®¤ 'en'
    """
    t = (text or "").strip()
    if _HAS_LANGDETECT:
        try:
            code = _langdetect(t)
            if code.startswith("zh"): 
                return "zh"
            if code.startswith("en"):
                return "en"
        except Exception:
            pass
    if _ratio_non_ascii(t) > 0.25:
        return "zh"
    zh_hit = _contains_any(t, _ZH_HINTS)
    en_hit = _contains_any(t, _EN_HINTS)
    if zh_hit and not en_hit:
        return "zh"
    if en_hit and not zh_hit:
        return "en"
    return "en"

# =================== Prompt æ¨¡æ¿ ===================
EN_RESUME_PROMPT = """You are an expert resume editor. KEEP THE OUTPUT IN ENGLISH.
Rewrite the resume content to be concise, quantified and aligned to the target JD.
- Use strong action verbs and measurable outcomes
- Keep neutral tone for UK graduate/entry roles
- Do NOT invent experience
Return ONLY the optimized resume text.
"""
ZH_RESUME_PROMPT = """ä½ æ˜¯èµ„æ·±ç®€å†ä¼˜åŒ–é¡¾é—®ã€‚è¯·å…¨ç¨‹ä½¿ç”¨ã€ä¸­æ–‡ã€‘è¾“å‡ºï¼Œå¹¶ä¿æŒä¸“ä¸šã€ç²¾ç‚¼ã€å¯é‡åŒ–ã€ä¸ç›®æ ‡JDé«˜åº¦åŒ¹é…ã€‚
- ä½¿ç”¨åŠ¨è¯å¼€å¤´ä¸é‡åŒ–ç»“æœ
- ä¸æ–°å¢æˆ–æœæ’°ç»å†
- ä¸è¦è¾“å‡ºè§£é‡Šæˆ–å®¢å¥—è¯
åªè¿”å›ã€ä¼˜åŒ–åçš„ç®€å†æ­£æ–‡ã€‘ã€‚
"""
EN_CL_PROMPT = """Write a concise one-page UK-style cover letter in ENGLISH tailored to the target JD and the resume.
- Clear structure: opening, 2â€“3 achievements aligned to JD, closing
- Measurable results, no fluff, no repetition of resume
Return ONLY the letter text.
"""
ZH_CL_PROMPT = """è¯·ç”¨ã€ä¸­æ–‡ã€‘æ’°å†™ä¸€é¡µå†…çš„æ±‚èŒä¿¡ï¼Œç»“åˆç®€å†ä¸ç›®æ ‡JDï¼š
- ç»“æ„æ¸…æ™°ï¼šå¼€åœºã€2â€“3æ¡ä¸JDé«˜åº¦åŒ¹é…çš„é‡åŒ–æˆæœã€ç»“å°¾
- ä¸“ä¸šä¸å †è¯ï¼Œä¸é‡å¤ç®€å†åŸå¥
åªè¿”å›æ±‚èŒä¿¡æ­£æ–‡ã€‚
"""

def get_prompts(lang: str):
    if lang == "zh":
        return ZH_RESUME_PROMPT, ZH_CL_PROMPT, "åŠ¡å¿…ä½¿ç”¨ä¸­æ–‡è¾“å‡ºï¼Œä¸”ä¸è¦æ··ç”¨è‹±æ–‡ã€‚"
    return EN_RESUME_PROMPT, EN_CL_PROMPT, "Always respond in English."

# =================== è§£æç®€å† ===================
def read_docx(file_bytes: bytes) -> str:
    doc = Document(io.BytesIO(file_bytes))
    paras = [(p.text or "").strip() for p in doc.paragraphs]
    return "\n".join([t for t in paras if t])

def read_pdf(file_bytes: bytes) -> str:
    text = []
    with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
        for page in pdf.pages:
            try:
                t = page.extract_text() or ""
                if t:
                    text.append(t)
            except Exception:
                pass
    return "\n".join(text)

def pdf_ocr(file_bytes: bytes) -> str:
    if not _HAS_OCR:
        return ""
    pages = convert_from_bytes(file_bytes, fmt="png")
    out = []
    for img in pages:
        txt = pytesseract.image_to_string(img, lang="chi_sim+eng")
        if txt:
            out.append(txt)
    return "\n".join(out)

def parse_resume(uploaded_file, use_ocr: bool) -> Tuple[str, str]:
    file_bytes = uploaded_file.read()
    name = uploaded_file.name.lower()
    if name.endswith(".pdf"):
        txt = read_pdf(file_bytes)
        if use_ocr and (not txt or len(txt) < 50):
            txt_ocr = pdf_ocr(file_bytes)
            if txt_ocr and len(txt_ocr) > len(txt):
                txt = txt_ocr
        return txt, "pdf"
    elif name.endswith(".docx"):
        return read_docx(file_bytes), "docx"
    else:
        try:
            return file_bytes.decode("utf-8", errors="ignore"), "txt"
        except Exception:
            return "", "txt"

# =================== OpenAI è°ƒç”¨ ===================
def call_openai(messages, temperature=0.2) -> str:
    client = get_openai_client()
    model = get_model_name()
    resp = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=temperature,
    )
    return (resp.choices[0].message.content or "").strip()

# =================== å¯¼å‡º ===================
def export_docx(text: str, title: Optional[str] = None) -> bytes:
    doc = Document()
    if title:
        doc.add_heading(title, level=1)
    for line in (text or "").splitlines():
        doc.add_paragraph(line)
    out = io.BytesIO()
    doc.save(out)
    out.seek(0)
    return out.getvalue()

def export_pdf_simple(text: str, title: Optional[str] = None) -> bytes:
    if not _HAS_PDF:
        return b""
    buf = io.BytesIO()
    c = canvas.Canvas(buf, pagesize=A4)
    width, height = A4
    y = height - 20 * mm
    if title:
        c.setFont("Helvetica-Bold", 14)
        c.drawString(20 * mm, y, title)
        y -= 12 * mm
    c.setFont("Helvetica", 10)
    for line in (text or "").splitlines():
        if y < 20 * mm:
            c.showPage()
            y = height - 20 * mm
            c.setFont("Helvetica", 10)
        c.drawString(20 * mm, y, line[:110])
        y -= 6 * mm
    c.save()
    buf.seek(0)
    return buf.getvalue()

# =================== åˆå§‹åŒ–çŠ¶æ€ï¼ˆé˜²æ­¢ä¸‹è½½åç»“æœä¸¢å¤±ï¼‰ ===================
if "opt_resume" not in st.session_state:
    st.session_state.opt_resume = ""
if "opt_cl" not in st.session_state:
    st.session_state.opt_cl = ""
if "export_title" not in st.session_state:
    st.session_state.export_title = "Optimized_Resume"
if "resume_lang" not in st.session_state:
    st.session_state.resume_lang = "en"

# =================== UI ===================
st.markdown("## ğŸ§  AI æ™ºèƒ½ç®€å†ä¼˜åŒ–")
st.caption("ä¸Šä¼ ç®€å†ï¼ŒAI å°†æ ¹æ® JD ä¸€é”®ä¼˜åŒ–ï¼›å¯é€‰ç”Ÿæˆæ±‚èŒä¿¡ï¼ˆCover Letterï¼Œè¯­è¨€è‡ªåŠ¨éšç®€å†ï¼‰ã€‚")

colL, colR = st.columns([1, 1])
with colL:
    uploaded = st.file_uploader("ä¸Šä¼ ç®€å†ï¼ˆPDF æˆ– DOCXï¼‰", type=["pdf", "docx", "txt"])
with colR:
    jd_text = st.text_area("ç²˜è´´ç›®æ ‡èŒä½ JDï¼ˆå¯æ‰¹é‡ï¼Œç”¨åˆ†éš”ï¼‰", height=180, placeholder="è´´ä¸Š JD æ–‡æœ¬â€¦â€¦")

st.divider()

# ä¾§è¾¹æ è®¾ç½®ï¼ˆå¢å¼ºç‚¹å¯è¾“å…¥ âœ…ï¼‰
with st.sidebar:
    st.markdown("### è®¾ç½®")
    refine_pills = st.multiselect(
        "ç²¾ä¿®ä¾§é‡",
        ["ä¸šåŠ¡å½±å“", "æ²Ÿé€šåä½œ", "é¢†å¯¼åŠ›", "æŠ€æœ¯æ·±åº¦", "æ•°æ®é©±åŠ¨"],
        default=["ä¸šåŠ¡å½±å“"]
    )
    enhance_text = st.text_input(
        "å¢å¼ºç‚¹ï¼ˆå¯è‡ªå®šä¹‰ï¼‰",
        value="æ•°æ®é©±åŠ¨ã€å¯é‡åŒ–ã€å…³é”®è¯å¥‘åˆ",
        help="å°†ä½œä¸ºä¼˜åŒ–åå¥½æç¤ºç»™æ¨¡å‹"
    )
    gen_cl = st.checkbox("ç”Ÿæˆæ±‚èŒä¿¡ï¼ˆCover Letterï¼Œè‡ªåŠ¨éšç®€å†è¯­è¨€ï¼‰", value=True)
    use_ocr = st.checkbox("å¯ç”¨ OCRï¼ˆæ‰«æ PDFï¼‰", value=False)
    st.markdown("---")
    st.caption("æœ¬åº”ç”¨ä»…ç”¨äºæ¼”ç¤º/æ ·ä¾‹ä½¿ç”¨ï¼Œå—ç‰ˆæƒä¿æŠ¤ã€‚ä»…ä¾›ä¸ªäººæ±‚èŒä½¿ç”¨ï¼Œç¦æ­¢æœªæˆæƒå¤åˆ¶ã€çˆ¬å–æˆ–å•†ç”¨ã€‚")

# è§£æç®€å†
if uploaded:
    resume_text, ftype = parse_resume(uploaded, use_ocr)
    if not resume_text.strip():
        st.warning("æœªèƒ½ä»æ–‡ä»¶ä¸­è§£æå‡ºæ–‡æœ¬ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æˆ–æ‰“å¼€ OCR è¯•è¯•ã€‚")
    else:
        base = re.sub(r"\.(pdf|docx|txt)$", "", uploaded.name, flags=re.I)
        st.session_state.export_title = base or "Optimized_Resume"
else:
    resume_text, ftype = "", ""

# é¢„è§ˆåŒº
if resume_text:
    with st.expander("ğŸ“„ ç®€å†æ–‡æœ¬é¢„è§ˆ", expanded=False):
        st.text_area("æå–ç»“æœï¼ˆå‰ 3000 å­—ï¼‰", resume_text[:3000], height=220)

# è‡ªåŠ¨è¯­è¨€æ£€æµ‹
resume_lang = detect_lang_en_zh(resume_text) if resume_text else st.session_state.get("resume_lang", "en")
st.session_state.resume_lang = resume_lang

with st.expander("ğŸŒ è¯­è¨€è‡ªåŠ¨è¯†åˆ«", expanded=True):
    st.markdown(f"æ£€æµ‹åˆ°å½“å‰ç®€å†è¯­è¨€ï¼š**{'ä¸­æ–‡' if resume_lang == 'zh' else 'English'}**")
    colA, colB = st.columns(2)
    if colA.toggle("è‹¥è¯†åˆ«é”™è¯¯ï¼Œå¼ºåˆ¶æ”¹ä¸ºä¸­æ–‡", value=False, key="force_zh"):
        resume_lang = "zh"; st.session_state.resume_lang = "zh"
    if colB.toggle("è‹¥è¯†åˆ«é”™è¯¯ï¼Œå¼ºåˆ¶æ”¹ä¸ºè‹±æ–‡", value=False, key="force_en"):
        resume_lang = "en"; st.session_state.resume_lang = "en"

# ä¸€é”®ç”Ÿæˆ
btn = st.button("ğŸª„ ä¸€é”®ç”Ÿæˆ", type="primary", use_container_width=True, disabled=(not uploaded))

opt_resume = ""
opt_cl = ""

if btn and uploaded and resume_text.strip():
    resume_prompt, cl_prompt, system_instruction = get_prompts(resume_lang)

    # ç»“åˆä¾§è¾¹æ åå¥½ï¼ˆå¢å¼ºç‚¹åˆå¹¶ï¼‰
    prefs = ", ".join(refine_pills) if refine_pills else ""
    addon = f"{'ï¼›' if prefs and resume_lang=='zh' else '; '}" if prefs else ""
    enhance = f"{enhance_text.strip()}" if enhance_text.strip() else ""
    pref_sentence = (prefs + addon + enhance).strip()
    if resume_lang == "en":
        prefer_line = f"\n\nPreference: please emphasize {pref_sentence or 'impact & clarity'}."
    else:
        prefer_line = f"\n\nåå¥½ï¼šè¯·æ›´çªå‡º {pref_sentence or 'æ•°æ®é©±åŠ¨ã€å¯é‡åŒ–ã€å…³é”®è¯å¥‘åˆ'}ã€‚"

    with st.spinner("æ­£åœ¨ä¼˜åŒ–ç®€å†..."):
        messages = [
            {"role": "system", "content": system_instruction},
            {"role": "user", "content": resume_prompt + prefer_line},
            {"role": "user", "content": f"Resume:\n{resume_text}\n\nTarget JD:\n{jd_text or ''}"}
        ]
        try:
            opt_resume = call_openai(messages, temperature=0.2)
        except Exception as e:
            st.error(f"è°ƒç”¨æ¨¡å‹å¤±è´¥ï¼š{e}")
            opt_resume = ""

    if gen_cl and opt_resume:
        with st.spinner("æ­£åœ¨ç”Ÿæˆæ±‚èŒä¿¡..."):
            _, cl_prompt, system_instruction = get_prompts(resume_lang)
            cl_messages = [
                {"role": "system", "content": system_instruction},
                {"role": "user", "content": cl_prompt},
                {"role": "user", "content": f"Resume:\n{opt_resume}\n\nTarget JD:\n{jd_text or ''}"}
            ]
            try:
                opt_cl = call_openai(cl_messages, temperature=0.2)
            except Exception as e:
                st.error(f"ç”Ÿæˆæ±‚èŒä¿¡å¤±è´¥ï¼š{e}")
                opt_cl = ""

    # âœ… å†™å…¥çŠ¶æ€ï¼Œé¿å…ä¸‹è½½è§¦å‘é‡è·‘åä¸¢å¤±
    if opt_resume:
        st.session_state.opt_resume = opt_resume
    if gen_cl and opt_cl:
        st.session_state.opt_cl = opt_cl

# âœ… å±•ç¤ºä¸å¯¼å‡ºï¼ˆä½¿ç”¨çŠ¶æ€ä¸­çš„ç»“æœï¼Œé˜²æ­¢ä¸‹è½½åé‡è·‘å˜ç©ºï¼‰
opt_resume = st.session_state.get("opt_resume", "")
opt_cl = st.session_state.get("opt_cl", "")
export_title = st.session_state.get("export_title", "Optimized_Resume")

if opt_resume:
    tabs = ["â­ ä¼˜åŒ–åç®€å†"]
    if gen_cl and opt_cl:
        tabs.append("ğŸ“„ æ±‚èŒä¿¡ï¼ˆCover Letterï¼‰")
    tabs.append("ğŸ“¤ å¯¼å‡º")
    t0, *rest = st.tabs(tabs)

    with t0:
        st.markdown(opt_resume.replace("\n", "  \n"))

    idx = 0
    if gen_cl and opt_cl:
        with rest[0]:
            st.markdown(opt_cl.replace("\n", "  \n"))
        idx = 1

    with rest[idx]:
        # DOCX å¯¼å‡º
        st.download_button(
            "â¬‡ï¸ ä¸‹è½½ç®€å†ï¼ˆDOCXï¼‰",
            data=export_docx(opt_resume, title=None),
            file_name=f"{export_title}.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            use_container_width=True,
            key="dl_resume_docx"
        )
        # TXT å¯¼å‡º
        st.download_button(
            "â¬‡ï¸ ä¸‹è½½ç®€å†ï¼ˆTXTï¼‰",
            data=opt_resume.encode("utf-8"),
            file_name=f"{export_title}.txt",
            mime="text/plain",
            use_container_width=True,
            key="dl_resume_txt"
        )
        # PDFï¼ˆè‹¥å¯ç”¨ï¼‰
        if _HAS_PDF:
            pdf_bytes = export_pdf_simple(opt_resume, title=None)
            if pdf_bytes:
                st.download_button(
                    "â¬‡ï¸ ä¸‹è½½ç®€å†ï¼ˆPDFï¼‰",
                    data=pdf_bytes,
                    file_name=f"{export_title}.pdf",
                    mime="application/pdf",
                    use_container_width=True,
                    key="dl_resume_pdf"
                )

        if gen_cl and opt_cl:
            st.subheader("æ±‚èŒä¿¡ï¼ˆCover Letterï¼‰")
            st.download_button(
                "â¬‡ï¸ ä¸‹è½½æ±‚èŒä¿¡ï¼ˆDOCXï¼‰",
                data=export_docx(opt_cl, title=None),
                file_name=f"{export_title}_CoverLetter.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                use_container_width=True,
                key="dl_cl_docx"
            )
            st.download_button(
                "â¬‡ï¸ ä¸‹è½½æ±‚èŒä¿¡ï¼ˆTXTï¼‰",
                data=opt_cl.encode("utf-8"),
                file_name=f"{export_title}_CoverLetter.txt",
                mime="text/plain",
                use_container_width=True,
                key="dl_cl_txt"
            )
            if _HAS_PDF:
                cl_pdf = export_pdf_simple(opt_cl, title=None)
                if cl_pdf:
                    st.download_button(
                        "â¬‡ï¸ ä¸‹è½½æ±‚èŒä¿¡ï¼ˆPDFï¼‰",
                        data=cl_pdf,
                        file_name=f"{export_title}_CoverLetter.pdf",
                        mime="application/pdf",
                        use_container_width=True,
                        key="dl_cl_pdf"
                    )

st.caption("å¦‚é‡è¾“å‡ºè¯­è¨€ä¸åŒ¹é…ï¼Œè¯·åœ¨â€œè¯­è¨€è‡ªåŠ¨è¯†åˆ«â€ä¸­å¼ºåˆ¶åˆ‡æ¢åå†ç‚¹ä¸€æ¬¡ç”Ÿæˆã€‚")