import os
import io
from uuid import uuid4
from datetime import datetime

import streamlit as st
from openai import OpenAI
from langdetect import detect

import pdfplumber
from docx import Document

# ============ Streamlit åŸºç¡€é…ç½®ï¼ˆå¿…é¡»æ˜¯ç¬¬ä¸€ä¸ª st è°ƒç”¨ï¼‰ ============
st.set_page_config(
    page_title="AI æ™ºèƒ½ç®€å†ä¼˜åŒ–",
    page_icon="ğŸ§ ",
    layout="wide",
)

# ============ å®‰å…¨å¯¼å…¥ analyticsï¼ˆGoogle Sheet & Slackï¼‰ ============
try:
    from analytics import log_event, log_feedback, log_error
except Exception:
    # å¦‚æœ analytics è¿˜æ²¡é…ç½®å¥½ï¼Œä¸é˜»å¡æ­£å¸¸åŠŸèƒ½
    def log_event(*args, **kwargs):
        pass

    def log_feedback(*args, **kwargs):
        pass

    def log_error(*args, **kwargs):
        pass


# ============ OpenAI å®¢æˆ·ç«¯ ============
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
MODEL_NAME = os.getenv("MODEL_NAME", "gpt-4o-mini")

if OPENAI_API_KEY:
    client = OpenAI(api_key=OPENAI_API_KEY)
else:
    client = None

# ============ Session çº§åˆ«ä¿¡æ¯ ============
if "sid" not in st.session_state:
    st.session_state["sid"] = str(uuid4())

SESSION_ID = st.session_state["sid"]

# é¦–æ¬¡æ‰“å¼€é¡µé¢åŸ‹ç‚¹
log_event(
    "page_view",
    {
        "sid": SESSION_ID,
        "ts": datetime.utcnow().isoformat(),
        "page": "resume_optimizer",
    },
)


# ============ ä¸€äº›å·¥å…·å‡½æ•° ============

def read_docx(file_bytes: bytes) -> str:
    bio = io.BytesIO(file_bytes)
    doc = Document(bio)
    lines = []
    for para in doc.paragraphs:
        text = para.text.strip()
        if text:
            lines.append(text)
    return "\n".join(lines)


def read_pdf(file_bytes: bytes) -> str:
    text_chunks = []
    bio = io.BytesIO(file_bytes)
    with pdfplumber.open(bio) as pdf:
        for page in pdf.pages:
            t = page.extract_text() or ""
            t = t.strip()
            if t:
                text_chunks.append(t)
    return "\n\n".join(text_chunks)


def detect_lang(text: str) -> str:
    try:
        lang = detect(text)
        if lang.startswith("zh"):
            return "zh"
        else:
            return "en"
    except Exception:
        # é»˜è®¤ä¸­æ–‡
        return "zh"


def build_prompt(
    cv_text: str,
    jd_text: str,
    focus_tags,
    custom_points: str,
    need_cover_letter: bool,
) -> tuple[str, str]:
    """
    è¿”å› (system_prompt, user_prompt)
    """
    lang = detect_lang(cv_text + "\n" + jd_text)

    if lang == "zh":
        system_prompt = (
            "ä½ æ˜¯ä¸€åèµ„æ·±æ±‚èŒé¡¾é—®ï¼Œæ“…é•¿æ ¹æ®å€™é€‰äººçš„ç®€å†ä¸ç›®æ ‡èŒä½ JDï¼Œ"
            "æå‡ç®€å†åŒ¹é…åº¦ä¸ä¸“ä¸šåº¦ï¼ŒåŒæ—¶åœ¨éœ€è¦æ—¶æ’°å†™é«˜è´¨é‡æ±‚èŒä¿¡ã€‚"
            "ä½ éœ€è¦åœ¨ä¿ç•™äº‹å®çœŸå®æ€§çš„å‰æä¸‹ï¼Œä¼˜åŒ–è¡¨è¿°ã€é‡åŒ–æˆæœã€çªå‡ºä¸ JD çš„åŒ¹é…åº¦ã€‚"
        )
        focus_text = "ã€".join(focus_tags) if focus_tags else "ç»¼åˆä¼˜åŒ–"
        user_prompt = f"""
ã€ä»»åŠ¡è¯­è¨€ã€‘è¯·å…¨ç¨‹ä½¿ç”¨ä¸å€™é€‰äººç®€å†ç›¸åŒçš„è¯­è¨€ï¼ˆå½“å‰è‡ªåŠ¨è¯†åˆ«ä¸ºï¼š{"ä¸­æ–‡" if lang=="zh" else "è‹±æ–‡"}ï¼‰ã€‚

ã€ä¼˜åŒ–é‡ç‚¹ã€‘{focus_text}

ã€å€™é€‰äººåŸå§‹ç®€å†ã€‘
{cv_text}

ã€ç›®æ ‡èŒä½ JD æˆ– ç‰¹åˆ«ä¼˜åŒ–æŒ‡ä»¤ã€‘
{jd_text}

ã€è‡ªå®šä¹‰å¢å¼ºç‚¹ï¼ˆå¦‚æœä¸ºç©ºå¯ä»¥å¿½ç•¥ï¼‰ã€‘
{custom_points or "ï¼ˆæ— ï¼‰"}

ã€è¾“å‡ºè¦æ±‚ã€‘
1. å…ˆè¾“å‡ºã€ä¼˜åŒ–åç®€å†ã€‘ï¼ŒæŒ‰ç…§å¸¸è§ç®€å†ç»“æ„åˆ†æ®µï¼š
   - ä¸ªäººä¿¡æ¯ï¼ˆä¸è¦è™šæ„è”ç³»æ–¹å¼ï¼‰
   - æ•™è‚²èƒŒæ™¯
   - å®ä¹  / å·¥ä½œç»å†ï¼ˆæ¯æ®µç»å†ç”¨è¦ç‚¹åˆ—å‡ºï¼Œçªå‡ºèŒè´£ + é‡åŒ–æˆæœ + ä½¿ç”¨æŠ€èƒ½ï¼‰
   - é¡¹ç›®ç»å†ï¼ˆå¦‚æœ‰ï¼‰
   - æŠ€èƒ½ & è¯ä¹¦
2. è¯·ç‰¹åˆ«æ³¨æ„ï¼š
   - ä¸è¦è™šæ„å¹¶ä¸å­˜åœ¨çš„å…¬å¸ã€å­¦æ ¡ã€è¯ä¹¦æˆ–æ—¥æœŸï¼›
   - å¯ä»¥å¯¹å·²æœ‰ç»å†è¿›è¡Œæ›´ä¸“ä¸šçš„è¡¨è¾¾å’Œé‡ç»„ï¼›
   - å°½é‡ä¿ç•™åŸæœ¬çš„å…³é”®ä¿¡æ¯ï¼Œä½†é¿å…å•°å—¦ã€‚
3. å¦‚æœç”¨æˆ·å‹¾é€‰äº†ç”Ÿæˆæ±‚èŒä¿¡ï¼Œè¯·åœ¨æœ€åå†è¾“å‡ºä¸€ä¸ªã€æ±‚èŒä¿¡ã€‘æ¨¡å—ï¼š
   - ç”¨ 1~1.5 é¡µå·¦å³ç¯‡å¹…ï¼›
   - è¯´æ˜å€™é€‰äººä¸è¯¥èŒä½çš„åŒ¹é…åº¦ã€ä»£è¡¨æ€§ç»å†å’ŒåŠ¨æœºã€‚
4. è¾“å‡ºæ ¼å¼ç”¨æ¸…æ™°çš„å°æ ‡é¢˜å’Œé¡¹ç›®ç¬¦å·ï¼Œé€‚åˆç›´æ¥å¤åˆ¶åˆ° Word ä¸­ä½¿ç”¨ã€‚
"""
    else:
        system_prompt = (
            "You are an experienced career consultant. "
            "Given a candidate's CV and a target job description, "
            "you will rewrite and improve the CV to better match the role, "
            "while keeping all information truthful. "
            "Optionally, you will also draft a tailored cover letter."
        )
        focus_text = ", ".join(focus_tags) if focus_tags else "overall optimisation"
        user_prompt = f"""
[Language] Please respond in the same language as the candidate's CV (currently detected as: {"Chinese" if lang=="zh" else "English"}).

[Focus]
{focus_text}

[Original CV]
{cv_text}

[Target Job Description or Extra Instructions]
{jd_text}

[Custom Emphasis / Extra Points]
{custom_points or "(none)"}

[Output Requirements]
1. First output an **Improved CV**:
   - Use standard sections (Profile, Education, Experience, Projects, Skills, Certifications, etc.).
   - For each experience, use bullet points focusing on responsibilities + quantified impact + skills/tech stack.
   - Do NOT fabricate employers, schools, degrees, or dates.
2. You may rephrase and reorganise content for clarity and impact, but do not invent fake achievements.
3. If the user has requested a cover letter, then add a **Cover Letter** section at the end:
   - About 1 page.
   - Clearly link the candidate's experience to the role requirements.
4. Make the structure easy to copy-paste into Word.
"""

    if not need_cover_letter:
        # æé†’æ¨¡å‹å¯ä»¥å¿½ç•¥æ±‚èŒä¿¡éƒ¨åˆ†
        if lang == "zh":
            user_prompt += "\nï¼ˆæœ¬æ¬¡ç”¨æˆ·æ²¡æœ‰å‹¾é€‰ç”Ÿæˆæ±‚èŒä¿¡ï¼Œå¦‚æ— ç‰¹åˆ«éœ€è¦å¯çœç•¥ã€æ±‚èŒä¿¡ã€‘æ¨¡å—ã€‚ï¼‰"
        else:
            user_prompt += "\n(The user did NOT request a cover letter this time; you may omit the Cover Letter section.)"

    return system_prompt, user_prompt


def call_openai(cv_text: str, jd_text: str, focus_tags, custom_points: str, need_cover_letter: bool) -> str:
    if not client:
        raise RuntimeError("OpenAI client not initialised. Please check OPENAI_API_KEY in Secrets.")

    system_prompt, user_prompt = build_prompt(
        cv_text=cv_text,
        jd_text=jd_text,
        focus_tags=focus_tags,
        custom_points=custom_points,
        need_cover_letter=need_cover_letter,
    )

    resp = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        temperature=0.4,
    )
    return resp.choices[0].message.content.strip()


def make_docx(text: str) -> bytes:
    """å°†çº¯æ–‡æœ¬å†™å…¥ä¸€ä¸ªç®€å•çš„ docxï¼Œè¿”å›äºŒè¿›åˆ¶å†…å®¹ã€‚"""
    doc = Document()
    for block in text.split("\n\n"):
        p = doc.add_paragraph()
        for line in block.split("\n"):
            p.add_run(line)
        # é¢å¤–ç©ºè¡Œäº¤ç»™ split å¤„ç†
    bio = io.BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio.read()


# ============ UI å¸ƒå±€ ============

# å·¦ä¾§ä¾§è¾¹æ 
with st.sidebar:
    st.markdown("### è®¾ç½®")

    st.caption("ï¼ˆå·¦ä¾§é€‰é¡¹ä»…å½±å“ç”Ÿæˆæ—¶çš„å¼ºè°ƒæ–¹å‘ï¼‰")

    focus_options = ["ä¸šåŠ¡å½±å“", "æ²Ÿé€šåä½œ", "æŠ€æœ¯æ·±åº¦", "æ•°æ®åˆ†æ", "é¢†å¯¼åŠ›æ½œåŠ›"]
    focus_tags = st.multiselect("ç²¾ä¿®ä¾§é‡ï¼ˆå¯å¤šé€‰ï¼‰", focus_options, default=["ä¸šåŠ¡å½±å“"])

    custom_points = st.text_area(
        "å¢å¼ºç‚¹ï¼ˆå¯è‡ªå®šä¹‰ï¼‰",
        value="ä¾‹å¦‚ï¼šå¼ºè°ƒæ•°æ®åˆ†æ/é‡åŒ–æˆæœï¼›çªå‡ºä¸ç›®æ ‡å²—ä½çš„åŒ¹é…ï¼›æˆ–å†™ä½œé£æ ¼è¦æ±‚ç­‰â€¦",
        height=120,
    )

    need_cover_letter = st.checkbox("ç”Ÿæˆæ±‚èŒä¿¡ï¼ˆCover Letterï¼‰", value=True)

    enable_ocr = st.checkbox("å¯ç”¨ OCRï¼ˆæ‰«æ PDFï¼‰", value=False)

    st.caption("ä»…ä¾›ä¸ªäººæ±‚èŒä½¿ç”¨ï¼Œç¦æ­¢å•†ç”¨ä¸çˆ¬å–ã€‚")

# å³ä¾§ä¸»åŒºåŸŸ
st.markdown("## ğŸ§  AI æ™ºèƒ½ç®€å†ä¼˜åŒ–")

st.markdown(
    "ä¸Šä¼ ç®€å†ï¼ŒAI å°†æ ¹æ® JD ä¸€é”®ä¼˜åŒ–ï¼›å¯é€‰ç”Ÿæˆæ±‚èŒä¿¡ï¼ˆCover Letterï¼Œè¯­è¨€è‡ªåŠ¨éšç®€å†ï¼‰ã€‚"
)

col_left, col_right = st.columns([1.05, 1.0])

with col_left:
    st.markdown("#### ä¸Šä¼ ç®€å†ï¼ˆPDF æˆ– DOCXï¼‰")
    uploaded_file = st.file_uploader(
        "Drag and drop file here",
        type=["pdf", "docx"],
        label_visibility="collapsed",
    )
    st.caption("æ”¯æŒ PDF / DOCXï¼Œå•æ–‡ä»¶ â‰¤ 50MBï¼›æ‰«æä»¶å¯å¯ç”¨ OCRã€‚")

with col_right:
    st.markdown("#### ç²˜è´´ç›®æ ‡èŒä½ JD æˆ– ä¼˜åŒ–æŒ‡ä»¤ï¼ˆå¯æ‰¹é‡ã€ç”¨åˆ†éš”ï¼‰")
    jd_text = st.text_area(
        "ä¾‹å¦‚ï¼šActuarial graduate role at Deloitte. ä¹Ÿå¯ä»¥ç›´æ¥å†™ä¼˜åŒ–æŒ‡ä»¤ï¼ˆå¦‚å¼ºè°ƒå“ªäº›æŠ€èƒ½ã€å†™ä½œé£æ ¼ç­‰ï¼‰",
        height=200,
        label_visibility="collapsed",
    )

st.markdown("---")
st.info("ğŸ’¡ æç¤ºï¼šå¯åœ¨å·¦ä¾§è®¾ç½®â€œç²¾ä¿®ä¾§é‡/å¢å¼ºç‚¹â€ï¼›è‹¥ PDF ä¸ºæ‰«æä»¶ï¼Œå¯å¼€å¯ OCRã€‚")

generate_btn = st.button("ğŸš€ ä¸€é”®ç”Ÿæˆ", use_container_width=True, type="primary")

st.markdown("---")

# åé¦ˆå…¥å£
with st.expander("ğŸ’¬ æäº¤åé¦ˆ / åŠŸèƒ½å»ºè®®ï¼ˆå¯é€‰ï¼‰"):
    fb_col1, fb_col2 = st.columns([2, 1])
    with fb_col1:
        feedback_text = st.text_area("åé¦ˆå†…å®¹ï¼ˆä¾‹å¦‚ï¼šå“ªé‡Œå¥½ç”¨ / å“ªé‡Œæœ‰ bug / å¸Œæœ›æ–°å¢ä»€ä¹ˆåŠŸèƒ½ï¼‰", height=120)
        contact = st.text_input("è”ç³»æ–¹å¼ï¼ˆå¯é€‰ï¼Œæ–¹ä¾¿æˆ‘å›å¤ä½ ï¼Œä¾‹å¦‚é‚®ç®±/å¾®ä¿¡ï¼‰")
    with fb_col2:
        if st.button("æäº¤åé¦ˆ"):
            if feedback_text.strip():
                log_feedback(
                    {
                        "sid": SESSION_ID,
                        "ts": datetime.utcnow().isoformat(),
                        "feedback": feedback_text.strip(),
                        "contact": contact.strip(),
                    }
                )
                st.success("æ„Ÿè°¢åé¦ˆï¼æˆ‘ä¼šå°½å¿«æŸ¥çœ‹å¹¶ä¼˜åŒ–ã€‚")
            else:
                st.warning("è¯·è¾“å…¥ä¸€äº›åé¦ˆå†…å®¹å†æäº¤ï½")


# é¡µé¢åº•éƒ¨ç‰ˆæƒ
st.caption("Â© 2025 AI Resume Optimizer | ä»…ä¾›ä¸ªäººæ±‚èŒä½¿ç”¨ï¼Œç¦æ­¢å•†ç”¨ä¸çˆ¬å–ã€‚")


# ============ ä¸»é€»è¾‘ï¼šç‚¹å‡» â€œä¸€é”®ç”Ÿæˆâ€ ============
def handle_generate():
    if not uploaded_file:
        st.warning("è¯·å…ˆä¸Šä¼ ä¸€ä»½ PDF æˆ– DOCX ç®€å†ã€‚")
        return

    # æ–‡ä»¶å¤§å°é™åˆ¶ 50MB
    if uploaded_file.size > 50 * 1024 * 1024:
        st.error("æ–‡ä»¶è¿‡å¤§ï¼Œè¯·æ§åˆ¶åœ¨ 50MB ä»¥å†…ã€‚")
        return

    if not jd_text.strip():
        st.warning("å»ºè®®ç²˜è´´è‡³å°‘ä¸€ä¸ªç›®æ ‡èŒä½ JD æˆ– ä¼˜åŒ–æŒ‡ä»¤ï¼Œè¿™æ ·æ•ˆæœä¼šæ›´å¥½å“¦ã€‚")

    # è¯»å–æ–‡ä»¶
    file_bytes = uploaded_file.read()
    file_name = uploaded_file.name.lower()

    try:
        if file_name.endswith(".docx"):
            cv_text = read_docx(file_bytes)
        elif file_name.endswith(".pdf"):
            if enable_ocr:
                st.info("å½“å‰ç‰ˆæœ¬æš‚æœªé›†æˆ OCR å¼•æ“ï¼Œå°†å…ˆå°è¯•ç›´æ¥è¯†åˆ« PDF æ–‡æœ¬ã€‚")
            cv_text = read_pdf(file_bytes)
        else:
            st.error("å½“å‰ä»…æ”¯æŒ PDF å’Œ DOCX æ ¼å¼ã€‚")
            return
    except Exception as e:
        log_error(
            "file_parse_error",
            {
                "sid": SESSION_ID,
                "file_name": uploaded_file.name,
                "error": str(e),
            },
        )
        st.error("è¯»å–ç®€å†æ–‡ä»¶æ—¶å‡ºé”™ï¼Œè¯·ç¡®è®¤æ–‡ä»¶æ˜¯å¦æ­£å¸¸æˆ–ç¨åé‡è¯•ã€‚")
        return

    if not cv_text.strip():
        st.error("æ²¡æœ‰ä»ç®€å†ä¸­è¯»å–åˆ°æœ‰æ•ˆæ–‡æœ¬ï¼Œå¯èƒ½æ˜¯æ‰«æä»¶æˆ–åŠ å¯†æ–‡ä»¶ã€‚")
        return

    with st.spinner("AI æ­£åœ¨ä¸ºä½ ä¼˜åŒ–ç®€å†ï¼Œè¯·ç¨å€™â€¦"):
        try:
            result_text = call_openai(
                cv_text=cv_text,
                jd_text=jd_text,
                focus_tags=focus_tags,
                custom_points=custom_points,
                need_cover_letter=need_cover_letter,
            )
        except Exception as e:
            log_error(
                "openai_error",
                {
                    "sid": SESSION_ID,
                    "error": str(e),
                },
            )
            st.error("è°ƒç”¨ AI æ¥å£æ—¶å‡ºé”™ï¼Œè¯·æ£€æŸ¥ API Key æˆ–ç¨åé‡è¯•ã€‚")
            return

    # æˆåŠŸåŸ‹ç‚¹
    log_event(
        "generate_success",
        {
            "sid": SESSION_ID,
            "ts": datetime.utcnow().isoformat(),
            "file_name": uploaded_file.name,
            "file_size": uploaded_file.size,
            "need_cover_letter": need_cover_letter,
            "focus_tags": focus_tags,
        },
    )

    st.markdown("### âœ… ç”Ÿæˆç»“æœï¼ˆå¯ç›´æ¥å¤åˆ¶æˆ–ä¸‹è½½ä¸º Wordï¼‰")
    st.markdown(result_text)

    # å¯¼å‡º Word
    docx_bytes = make_docx(result_text)
    safe_name = os.path.splitext(uploaded_file.name)[0]
    export_filename = f"{safe_name}_AIä¼˜åŒ–ç‰ˆ.docx"

    st.download_button(
        label="â¬‡ï¸ ä¸‹è½½ Word ç‰ˆæœ¬ï¼ˆDOCXï¼‰",
        data=docx_bytes,
        file_name=export_filename,
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    )


if generate_btn:
    handle_generate()