# -*- coding: utf-8 -*-
# AI æ™ºèƒ½ç®€å†ä¼˜åŒ–ï¼ˆå«ï¼šå·¦ä¾§ç²¾ä¿®ä¾§é‡/å¢å¼ºç‚¹/æ±‚èŒä¿¡/OCRï¼›ä¸Šä¼ â‰¤50MBï¼Œä»…PDF/DOCXï¼›è‡ªåŠ¨è¯†åˆ«è¯­è¨€ï¼›éšè—â€œ200MBâ€æç¤ºï¼‰

import os
import io
import re
import time
import pdfplumber
import streamlit as st
from dotenv import load_dotenv
from docx import Document

# ---- å¯é€‰ä¾èµ–ï¼ˆä¸å®‰è£…ä¹Ÿèƒ½è·‘ï¼‰ ----
_HAS_OCR = True
try:
    from pdf2image import convert_from_bytes
    import pytesseract
except Exception:
    _HAS_OCR = False

_HAS_PDF = True
try:
    from reportlab.pdfgen import canvas
    from reportlab.lib.pagesizes import A4
except Exception:
    _HAS_PDF = False

# ---- OpenAI å®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼Œæ²¡æœ‰ä¹Ÿèƒ½è·‘ Demoï¼‰----
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
client = None
if OPENAI_API_KEY:
    try:
        from openai import OpenAI
        client = OpenAI(api_key=OPENAI_API_KEY)
    except Exception:
        client = None

# ---- å¸¸é‡ä¸å·¥å…· ----
MAX_SIZE = 50 * 1024 * 1024  # 50MB

def detect_is_cjk(text: str) -> bool:
    """ç®€å•ä¸­æ–‡æ£€æµ‹ï¼šå«ä¸­æ–‡å­—ç¬¦çš„å æ¯”>20%å³è®¤ä¸ºä¸­æ–‡ã€‚"""
    if not text:
        return False
    cjk_count = len(re.findall(r'[\u4e00-\u9fff]', text))
    return (cjk_count / max(len(text), 1)) > 0.2

def lang_of(text: str) -> str:
    return "zh" if detect_is_cjk(text) else "en"

def read_docx(file_bytes: bytes) -> str:
    doc = Document(io.BytesIO(file_bytes))
    return "\n".join(p.text for p in doc.paragraphs if p.text.strip())

def read_pdf_text(file_bytes: bytes, enable_ocr: bool = False) -> str:
    """ä¼˜å…ˆç»“æ„åŒ–æå–ï¼›æå–ä¸åˆ°å†ç”¨ OCRï¼ˆå¦‚æœå®‰è£…äº†ä¸”å¼€å¯ï¼‰"""
    chunks = []
    with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
        for page in pdf.pages:
            t = page.extract_text() or ""
            if t.strip():
                chunks.append(t)
    text = "\n".join(chunks).strip()

    if not text and enable_ocr and _HAS_OCR:
        try:
            images = convert_from_bytes(file_bytes)
            ocr_text = []
            for img in images:
                ocr_text.append(pytesseract.image_to_string(img))
            text = "\n".join(ocr_text)
        except Exception:
            pass
    return text.strip()

def build_prompt(
    resume_text: str,
    jd_text: str,
    language: str,
    focus_tags: list[str],
    enhancement_notes: str,
    need_cover_letter: bool
) -> str:
    """æ„å»ºç»™æ¨¡å‹çš„ç³»ç»Ÿ/ç”¨æˆ·åˆå¹¶æç¤ºè¯ï¼ˆç®€åŒ–æˆä¸€ä¸ªå¤§ user æŒ‡ä»¤ï¼Œå…¼å®¹æ€§å¥½ï¼‰"""
    zh = (language == "zh")
    lines = []
    if zh:
        lines.append("ä½ æ˜¯ä¸€åèµ„æ·±ç®€å†é¡¾é—®ï¼Œè¯·åŸºäºç”¨æˆ·ä¸Šä¼ çš„ç®€å†ä¸ç›®æ ‡èŒä½ï¼Œè¾“å‡ºåŒè¯­è¨€çš„ä¼˜åŒ–ç®€å†ï¼ˆçº¯æ–‡æœ¬åˆ†æ®µï¼‰ã€‚")
        lines.append("è¦æ±‚ï¼šç»“æ„æ¸…æ™°ã€é‡åŒ–ç»“æœã€çªå‡ºå…³é”®è¯ã€å»é™¤å†—ä½™ï¼›ä¸è¦ä½¿ç”¨èŠ±å“¨ç¬¦å·ï¼Œä¸è¦è™šæ„ç»å†ã€‚")
        if need_cover_letter:
            lines.append("å¦å¤–ï¼Œè¯·ç”Ÿæˆä¸èŒä½åŒ¹é…çš„è‹±æ–‡æˆ–ä¸­æ–‡æ±‚èŒä¿¡ï¼ˆæ ¹æ®ç®€å†è¯­è¨€è‡ªåŠ¨å†³å®šï¼‰ï¼Œé£æ ¼ä¸“ä¸šç®€æ´ã€‚")
    else:
        lines.append("You are a senior resume consultant. Based on the user's resume and target JD, output an improved resume (same language).")
        lines.append("Requirements: clear structure, quantified outcomes, highlight keywords, remove fluff; no fancy symbols; no fabrication.")
        if need_cover_letter:
            lines.append("Also generate a matching cover letter in the same language. Keep it concise and professional.")

    if focus_tags:
        if zh:
            lines.append(f"ã€ç²¾ä¿®ä¾§é‡ã€‘è¯·ç‰¹åˆ«çªå‡ºï¼š{', '.join(focus_tags)}ã€‚")
        else:
            lines.append(f"[Refinement Focus] Emphasize: {', '.join(focus_tags)}.")

    if enhancement_notes.strip():
        if zh:
            lines.append(f"ã€å¢å¼ºç‚¹ã€‘{enhancement_notes.strip()}")
        else:
            lines.append(f"[Custom Emphasis] {enhancement_notes.strip()}")

    if zh:
        lines.append("\nã€ç”¨æˆ·ç®€å†ã€‘\n" + resume_text.strip())
        lines.append("\nã€ç›®æ ‡èŒä½/æŒ‡ä»¤ã€‘\n" + (jd_text.strip() if jd_text.strip() else "æ— "))
        lines.append("\nè¯·å…ˆè¾“å‡ºã€Šä¼˜åŒ–åçš„ç®€å†ã€‹ï¼Œè‹¥éœ€è¦å†è¾“å‡ºã€Šæ±‚èŒä¿¡ã€‹ã€‚")
    else:
        lines.append("\n[User Resume]\n" + resume_text.strip())
        lines.append("\n[Target JD / Instruction]\n" + (jd_text.strip() if jd_text.strip() else "N/A"))
        lines.append("\nFirst output the improved RESUME; then, if needed, output the COVER LETTER.")

    return "\n".join(lines)

def llm_generate(prompt: str, temperature: float = 0.4) -> str:
    """è°ƒç”¨ OpenAIï¼›æ—  key æ—¶è¿›å…¥ Demoã€‚"""
    if client is None:
        # Demo æ¨¡å¼ï¼šç›´æ¥å›æ˜¾ç»“æ„åŒ–ç¤ºä¾‹ï¼Œä¿è¯ä¸æŠ¥é”™
        return (
            "ã€æ¼”ç¤ºæ¨¡å¼ã€‘\n"
            "RESUME (Sample)\n"
            "- Optimized bullets with quantified outcomes...\n"
            "- Highlighted keywords matched to JD...\n\n"
            "COVER LETTER (Sample)\n"
            "Dear Hiring Manager, ...\n"
        )
    try:
        # gpt-4o-mini æˆæœ¬ä½ã€æ•ˆæœå¥½
        r = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a helpful, concise, and rigorous resume optimizer."},
                {"role": "user", "content": prompt},
            ],
            temperature=temperature,
        )
        return r.choices[0].message.content.strip()
    except Exception as e:
        return f"[LLM Error] {e}"

def to_docx(text: str) -> bytes:
    """ç®€æ´å†™å…¥ docxï¼ˆä¸ä½¿ç”¨ç²—ä½“/å¼•å· hackï¼Œé¿å…ä½ é‡åˆ°çš„â€œå¼•å·å˜ç²—ä½“â€ç°è±¡ï¼‰"""
    doc = Document()
    for block in re.split(r"\n\s*\n", text.strip()):
        doc.add_paragraph(block.strip())
    bio = io.BytesIO()
    doc.save(bio)
    return bio.getvalue()

def to_pdf(text: str) -> bytes:
    """ç®€å•è½¬ PDFï¼ˆå¦‚æœå®‰è£…äº† reportlabï¼‰ï¼Œå¦åˆ™è¿”å› None"""
    if not _HAS_PDF:
        return None
    bio = io.BytesIO()
    c = canvas.Canvas(bio, pagesize=A4)
    width, height = A4
    left, top, leading = 40, height - 50, 14

    # åˆ†é¡µæ‰“å°
    y = top
    for line in text.splitlines():
        # ç®€å•è‡ªåŠ¨æ¢é¡µ
        if y < 50:
            c.showPage()
            y = top
        c.drawString(left, y, line[:1000])  # é˜²æ­¢è¶…é•¿
        y -= leading
    c.save()
    return bio.getvalue()

# ---------------- UI ----------------
st.set_page_config(page_title="AI æ™ºèƒ½ç®€å†ä¼˜åŒ–", page_icon="ğŸ§ ", layout="wide")

# éšè—é»˜è®¤â€œLimit 200MB per fileâ€
st.markdown("""
<style>
div[data-testid="stFileUploader"] small,
div[data-testid="stFileUploader"] div:has(> small),
[data-testid="stFileUploadDropzone"] small,
[data-testid="stFileUploadDropzoneDescription"] {
  display: none !important;
}
section.main > div { padding-top: 1rem; }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ§  AI æ™ºèƒ½ç®€å†ä¼˜åŒ–")

# å·¦ä¾§æ 
with st.sidebar:
    st.markdown("### è®¾ç½®")
    # ç²¾ä¿®ä¾§é‡ï¼ˆå¤šé€‰ï¼‰
    focus = st.multiselect(
        "ç²¾ä¿®ä¾§é‡ï¼ˆå¯å¤šé€‰ï¼‰",
        options=["ä¸šåŠ¡å½±å“", "æ²Ÿé€šåä½œ", "æ•°æ®é©±åŠ¨", "é‡åŒ–æˆæœ", "å…³é”®å­—å¥‘åˆ", "é¡¹ç›®ç»éªŒ", "é¢†å¯¼åŠ›", "å®ä¹ /æ ¡æ‹›ä¸“é¡¹"],
        default=["ä¸šåŠ¡å½±å“"]
    )
    # å¢å¼ºç‚¹ï¼ˆè‡ªå®šä¹‰ï¼‰
    notes = st.text_area(
        "å¢å¼ºç‚¹ï¼ˆå¯è‡ªå®šä¹‰ï¼‰",
        placeholder="ä¾‹å¦‚ï¼šå¼ºè°ƒæ•°æ®åˆ†æã€é‡åŒ–æŒ‡æ ‡ï¼›çªå‡ºä¸ç›®æ ‡å²—ä½çš„åŒ¹é…ç‚¹ï¼›æˆ–å†™ä½œé£æ ¼è¦æ±‚ç­‰â€¦",
        height=100
    )
    need_cl = st.checkbox("ç”Ÿæˆæ±‚èŒä¿¡ï¼ˆCover Letterï¼‰", value=True)
    ocr_on = st.checkbox("å¯ç”¨ OCRï¼ˆæ‰«æ PDFï¼‰", value=False)
    st.caption("ä»…ä¾›ä¸ªäººæ±‚èŒä½¿ç”¨ï¼Œç¦æ­¢å•†ç”¨ä¸çˆ¬å–ã€‚")

# ä¸Šä¼ åŒº + JD/æŒ‡ä»¤
left, right = st.columns([1, 1])
with left:
    st.subheader("ä¸Šä¼ ç®€å†ï¼ˆPDF æˆ– DOCXï¼‰")
    up = st.file_uploader(
        label="",
        type=["pdf", "docx"],            # ä¸å…è®¸ txt
        accept_multiple_files=False,
        label_visibility="collapsed"
    )
    st.caption("æ”¯æŒ **PDF / DOCX** Â· å•ä¸ªæ–‡ä»¶ **â‰¤ 50MB** Â· æ‰«æä»¶å¯å¼€å¯ **OCR**")

with right:
    st.subheader("ç²˜è´´ç›®æ ‡èŒä½ JD æˆ–ä¼˜åŒ–æŒ‡ä»¤ï¼ˆå¯æ‰¹é‡ã€ç”¨åˆ†éš”ï¼‰")
    jd_text = st.text_area(
        "ä¾‹å¦‚ï¼šActuarial graduate role at Deloitte. è¯·é‡ç‚¹çªå‡ºæ•°æ®åˆ†æä¸å»ºæ¨¡èƒ½åŠ›ï¼›Cover Letter æ›´æ­£å¼ã€‚",
        placeholder="JD æˆ– ä¼˜åŒ–æŒ‡ä»¤ï¼›æ”¯æŒå¤šæ¡ï¼Œç”¨ç©ºè¡Œåˆ†éš”ã€‚",
        height=180,
        label_visibility="collapsed"
    )

st.markdown("â€”" * 60)

# ä¸€é”®ç”Ÿæˆ
btn = st.button("ğŸš€ ä¸€é”®ç”Ÿæˆ", use_container_width=True, type="primary")

# ---- å¤„ç†é€»è¾‘ ----
if btn:
    if not up:
        st.error("è¯·å…ˆä¸Šä¼ ç®€å†ï¼ˆPDF æˆ– DOCXï¼‰ã€‚")
        st.stop()
    if up.size > MAX_SIZE:
        st.error("æ–‡ä»¶è¿‡å¤§ï¼Œè¯·ä¸Šä¼  **â‰¤ 50MB** çš„ PDF æˆ– DOCXã€‚")
        st.stop()

    # è¯»å–æ–‡æœ¬
    with st.spinner("æ­£åœ¨è¯»å–ç®€å†æ–‡æœ¬â€¦"):
        ext = (up.name.split(".")[-1] or "").lower()
        raw = up.read()

        if ext == "docx":
            resume_text = read_docx(raw)
        elif ext == "pdf":
            resume_text = read_pdf_text(raw, enable_ocr=ocr_on)
        else:
            st.error("ä»…æ”¯æŒ PDF æˆ– DOCXã€‚")
            st.stop()

        if not resume_text.strip():
            st.error("æœªèƒ½è¯»å–åˆ°æœ‰æ•ˆæ–‡æœ¬ï¼šå¦‚æœæ˜¯æ‰«æä»¶ï¼Œè¯·åœ¨å·¦ä¾§å¯ç”¨ OCR å†è¯•ã€‚")
            st.stop()

    # è‡ªåŠ¨è¯†åˆ«è¯­è¨€
    language = lang_of(resume_text)
    zh = (language == "zh")
    st.info(f"æ£€æµ‹åˆ°ç®€å†è¯­è¨€ï¼š{'ä¸­æ–‡' if zh else 'English'}ã€‚å°†ä»¥åŒè¯­è¨€è¾“å‡ºã€‚")

    # å¤š JD æ‹†åˆ†ï¼ˆç©ºè¡Œåˆ†éš”ï¼‰ï¼Œé€æ¡ç”Ÿæˆ
    jd_blocks = [b.strip() for b in re.split(r"\n\s*\n", jd_text or "") if b.strip()]
    if not jd_blocks:
        jd_blocks = [""]  # è‹¥æ²¡JDï¼Œä¹Ÿèƒ½ä¼˜åŒ–åŸç®€å†

    results = []
    for idx, jd in enumerate(jd_blocks, start=1):
        with st.spinner(f"æ­£åœ¨ç”Ÿæˆï¼ˆ{idx}/{len(jd_blocks)}ï¼‰â€¦"):
            prompt = build_prompt(
                resume_text=resume_text,
                jd_text=jd,
                language=language,
                focus_tags=focus,
                enhancement_notes=notes,
                need_cover_letter=need_cl
            )
            llm_out = llm_generate(prompt)

        # å±•ç¤ºä¸ä¸‹è½½
        st.subheader(f"{'ç¬¬' + str(idx) + 'ä»½' if zh else 'Variant ' + str(idx)}")
        st.text_area("ç”Ÿæˆç»“æœï¼ˆé¢„è§ˆï¼‰", llm_out, height=300)

        # å¯¼å‡º DOCX
        docx_bytes = to_docx(llm_out)
        st.download_button(
            label="â¬‡ï¸ ä¸‹è½½ DOCX",
            data=docx_bytes,
            file_name=(f"ä¼˜åŒ–ç®€å†_{idx}.docx" if zh else f"resume_variant_{idx}.docx"),
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            use_container_width=True
        )

        # å¯é€‰ï¼šå¯¼å‡º PDFï¼ˆè‹¥å®‰è£… reportlabï¼‰
        pdf_bytes = to_pdf(llm_out)
        if pdf_bytes:
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½ PDFï¼ˆå¯é€‰ï¼‰",
                data=pdf_bytes,
                file_name=(f"ä¼˜åŒ–ç®€å†_{idx}.pdf" if zh else f"resume_variant_{idx}.pdf"),
                mime="application/pdf",
                use_container_width=True
            )

        st.markdown("---")

st.caption("Â© 2025 AI Resume Optimizer | ä»…ä¾›ä¸ªäººæ±‚èŒä½¿ç”¨ï¼Œç¦æ­¢å•†ç”¨ä¸çˆ¬å–ã€‚")