import os
import io
import re
from typing import Tuple

import streamlit as st
from dotenv import load_dotenv
from docx import Document
from openai import OpenAI

# ============= å¯é€‰ä¾èµ–ï¼ˆäº‘ç«¯å¯èƒ½ç¼ºï¼‰ =============
# pdfplumber å¸¸è§ä¸”è½»é‡ï¼›äº‘ç«¯é€šå¸¸å¯ç”¨
try:
    import pdfplumber
except Exception:
    pdfplumber = None

# OCR ä¾èµ–ï¼ˆäº‘ç«¯æœªå¿…è£…å¥½ï¼Œè¿è¡Œæ—¶å†åˆ¤æ–­ï¼‰
def _safe_import_ocr():
    try:
        from pdf2image import convert_from_bytes
        import pytesseract
        return convert_from_bytes, pytesseract
    except Exception:
        return None, None

# ============= é¡µé¢é…ç½® & æ ·å¼ä¿®å¤ï¼ˆé˜²æ ‡é¢˜é®æŒ¡ï¼‰ =============
st.set_page_config(page_title="AI æ™ºèƒ½ç®€å†ä¼˜åŒ–", page_icon="ğŸ§ ", layout="wide")
st.markdown("""
<style>
/* ä¿ç•™ Header é«˜åº¦ï¼Œé¿å…å†…å®¹è¢«é¡¶ä¸Šå» */
[data-testid="stHeader"]{visibility:visible;height:2.8rem;background:transparent;}
[data-testid="stToolbar"]{visibility:hidden;height:2.8rem;}
.block-container{padding-top:3.2rem!important;max-width:1200px;}
h1:first-child,.stMarkdown h1:first-child{margin-top:0.6rem!important;}
button[kind="primary"] { font-weight: 600; }
</style>
""", unsafe_allow_html=True)

# ============= åŠ è½½å¯†é’¥ & åˆå§‹åŒ– OpenAI =============
load_dotenv()
OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY", ""))
MODEL_NAME = st.secrets.get("MODEL_NAME", os.getenv("MODEL_NAME", "gpt-4o-mini"))

if not OPENAI_API_KEY:
    st.error("âš ï¸ æœªæ£€æµ‹åˆ° OPENAI_API_KEYã€‚è¯·åœ¨ Streamlit â†’ Settings â†’ Secrets æ·»åŠ ï¼šOPENAI_API_KEY = \"sk-...\"")
    client = None
else:
    client = OpenAI(api_key=OPENAI_API_KEY)

# ============= å·¥å…·å‡½æ•° =============
def detect_language(text: str) -> str:
    """ç®€å•æ£€æµ‹ï¼šä¸­æ–‡å¤šåˆ™ zhï¼Œå¦åˆ™ en"""
    zh = len(re.findall(r'[\u4e00-\u9fff]', text or ""))
    en = len(re.findall(r'[A-Za-z]', text or ""))
    return "zh" if zh > en else "en"

def _read_pdf_text(file_bytes: bytes) -> str:
    """ä¼˜å…ˆä½¿ç”¨ pdfplumber æå–æ–‡æœ¬"""
    if not pdfplumber:
        return ""
    text = []
    try:
        with pdfplumber.open(io.BytesIO(file_bytes)) as pdf:
            for p in pdf.pages:
                text.append(p.extract_text() or "")
    except Exception:
        return ""
    return "\n".join(text).strip()

def _ocr_pdf(file_bytes: bytes) -> str:
    """OCR è¯†åˆ«æ‰«æ PDFï¼ˆè‹¥ä¾èµ–ç¼ºå¤±åˆ™è¿”å›ç©ºï¼‰"""
    convert_from_bytes, pytesseract = _safe_import_ocr()
    if not (convert_from_bytes and pytesseract):
        return ""
    try:
        images = convert_from_bytes(file_bytes, dpi=300)
        parts = [pytesseract.image_to_string(im, lang="chi_sim+eng") for im in images]
        return "\n".join(parts).strip()
    except Exception:
        return ""

def read_resume(uploaded_file, use_ocr: bool) -> Tuple[str, str]:
    """
    è¯»å– PDF/DOCX æ–‡æœ¬ï¼›ä¸æ”¯æŒ TXTã€‚
    - PDFï¼špdfplumberï¼›è‹¥æ–‡æœ¬æå°‘ä¸” use_ocr=Trueï¼Œå°è¯• OCR
    - DOCXï¼špython-docx
    è¿”å› (æ–‡æœ¬, æ ¼å¼å)
    """
    name = uploaded_file.name.lower()

    uploaded_file.seek(0)
    raw_bytes = uploaded_file.read()
    uploaded_file.seek(0)

    if name.endswith(".pdf"):
        text = _read_pdf_text(raw_bytes)
        # æ–‡æœ¬æå°‘æ—¶å°è¯• OCRï¼ˆå¯é€‰ï¼‰
        if len(text) < 20 and use_ocr:
            ocr_text = _ocr_pdf(raw_bytes)
            if ocr_text:
                return ocr_text, "PDF(OCR)"
        if not text:
            raise ValueError("æœªèƒ½ä» PDF ä¸­æå–åˆ°æ–‡æœ¬ã€‚è‹¥ä¸ºæ‰«æä»¶ï¼Œè¯·å¼€å¯ OCR æˆ–æ›´æ¢æ›´æ¸…æ™°çš„æ–‡ä»¶ã€‚")
        return text, "PDF"

    elif name.endswith(".docx"):
        doc = Document(io.BytesIO(raw_bytes))
        text = "\n".join(p.text for p in doc.paragraphs if p.text).strip()
        if not text:
            raise ValueError("DOCX å†…å®¹ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ–‡ä»¶ã€‚")
        return text, "DOCX"

    # æ˜ç¡®æ‹’ç» TXT/å…¶ä»–æ ¼å¼
    raise ValueError("å½“å‰ç‰ˆæœ¬ä»…æ”¯æŒ PDF æˆ– DOCXã€‚")

def build_focus_instructions(focus_tags, custom_points, lang):
    """æ ¹æ®ä¾§æ é€‰é¡¹ç”Ÿæˆä¼˜åŒ–æŒ‡ä»¤ç‰‡æ®µ"""
    if not focus_tags and not custom_points:
        return ""
    if lang == "zh":
        parts = []
        if focus_tags:
            parts.append("è¯·åœ¨ä¼˜åŒ–ä¸­ç‰¹åˆ«å¼ºè°ƒä»¥ä¸‹ä¾§é‡ç‚¹ï¼š" + "ã€".join(focus_tags) + "ã€‚")
        if custom_points:
            parts.append("å…¶ä»–è‡ªå®šä¹‰è¦æ±‚ï¼š" + custom_points.strip())
        return "\n".join(parts)
    else:
        parts = []
        if focus_tags:
            parts.append("Please emphasise the following focus areas in the optimisation: " +
                         ", ".join(focus_tags) + ".")
        if custom_points:
            parts.append("Additional user notes: " + custom_points.strip())
        return "\n".join(parts)

def llm_optimize_resume(resume_text: str, jd_text: str, lang: str, focus_directives: str) -> str:
    """è°ƒç”¨æ¨¡å‹ç”Ÿæˆä¼˜åŒ–ç®€å†"""
    if not client:
        raise RuntimeError("OpenAI client æœªåˆå§‹åŒ–ã€‚è¯·é…ç½® OPENAI_API_KEYã€‚")
    prompt = f"""
You are a professional career consultant AI.
Optimise the following resume to better match the job description / user instructions.
Keep the same language as the resume: {"Chinese (ç®€ä½“ä¸­æ–‡)" if lang=="zh" else "English"}.
Focus on quantifiable achievements, clear structure, strong action verbs, ATS-friendly formatting.

[Job description or user instructions]
{jd_text or "(none)"}

[User focus directives]
{focus_directives or "(none)"}

[Original resume]
{resume_text}

[Output requirement]
Return ONLY the optimised resume text (no extra commentary).
"""
    rsp = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.6,
    )
    return (rsp.choices[0].message.content or "").strip()

def llm_cover_letter(resume_text: str, jd_text: str, lang: str, focus_directives: str) -> str:
    """è°ƒç”¨æ¨¡å‹ç”Ÿæˆæ±‚èŒä¿¡"""
    if not client:
        raise RuntimeError("OpenAI client æœªåˆå§‹åŒ–ã€‚è¯·é…ç½® OPENAI_API_KEYã€‚")
    prompt = f"""
Write a concise, compelling cover letter in {"Chinese (ç®€ä½“ä¸­æ–‡)" if lang=="zh" else "English"}.
Match the resume's background and the job needs.

[Job description or user instructions]
{jd_text or "(none)"}

[User focus directives]
{focus_directives or "(none)"}

[Resume]
{resume_text}

[Output requirement]
Return ONLY the cover letter body (no extra notes).
"""
    rsp = client.chat.completions.create(
        model=MODEL_NAME,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.6,
    )
    return (rsp.choices[0].message.content or "").strip()

def to_docx_bytes(text: str) -> bytes:
    """å°†çº¯æ–‡æœ¬å¯¼å‡ºä¸º .docx"""
    doc = Document()
    for line in (text or "").split("\n"):
        doc.add_paragraph(line)
    buf = io.BytesIO()
    doc.save(buf)
    buf.seek(0)
    return buf.getvalue()

# ============= SessionStateï¼ˆä¸‹è½½ä¸ä¸¢ï¼‰ =============
for k, v in {
    "optimized_resume": None,
    "cover_letter": None,
    "detected_lang": None,
    "last_file_format": None,
}.items():
    if k not in st.session_state:
        st.session_state[k] = v

# ============= å·¦ä¾§æ è®¾ç½® =============
st.sidebar.header("è®¾ç½®")
st.sidebar.caption("ä»¥ä¸‹é€‰é¡¹ä»…å½±å“ç”Ÿæˆç­–ç•¥")

FOCUS_OPTIONS = ["ä¸šåŠ¡å½±å“", "é‡åŒ–æˆæœ", "é¡¹ç›®ç®¡ç†", "æ²Ÿé€šåä½œ", "é¢†å¯¼åŠ›", "æŠ€æœ¯æ·±åº¦", "AI/æ•°æ®åˆ†æ", "ç ”ç©¶èƒ½åŠ›", "å®¢æˆ·ä»·å€¼"]
focus_tags = st.sidebar.multiselect("ç²¾ä¿®ä¾§é‡ï¼ˆå¯å¤šé€‰ï¼‰", FOCUS_OPTIONS, default=["ä¸šåŠ¡å½±å“", "é‡åŒ–æˆæœ"])

custom_points = st.sidebar.text_area(
    "å¢å¼ºç‚¹ï¼ˆå¯è‡ªå®šä¹‰ï¼‰",
    placeholder="ä¾‹å¦‚ï¼šçªå‡ºXè¡Œä¸šç»éªŒï¼›é‡åŒ–æ¯æ®µæˆæœï¼›å¼ºè°ƒè·¨å›¢é˜Ÿåä½œâ€¦",
    height=90
)

need_cl = st.sidebar.checkbox("ç”Ÿæˆæ±‚èŒä¿¡ï¼ˆCover Letterï¼‰", value=True)

use_ocr = st.sidebar.checkbox(
    "å¯ç”¨ OCRï¼ˆæ‰«æ PDFï¼‰",
    value=False,
    help="è‹¥ PDF æ˜¯æ‰«æä»¶ä¸”æå–ä¸åˆ°æ–‡æœ¬ï¼Œå¼€å¯åå°è¯•è¯†åˆ«ï¼ˆäº‘ç«¯è‹¥ç¼ºå°‘ä¾èµ–å°†è‡ªåŠ¨é™çº§å¹¶æç¤ºï¼‰ã€‚"
)

# ============= ä¸»ä½“åŒºåŸŸ =============
st.title("ğŸ§  AI æ™ºèƒ½ç®€å†ä¼˜åŒ–")
st.caption("ä¸Šä¼ ç®€å†ï¼ŒAI å°†æ ¹æ® JD/æŒ‡ä»¤ä¸€é”®ä¼˜åŒ–ï¼›å¯é€‰ç”Ÿæˆæ±‚èŒä¿¡ï¼ˆCover Letterï¼Œè¯­è¨€è‡ªåŠ¨éšç®€å†ï¼‰ã€‚")

col_left, col_right = st.columns([1, 1])
with col_left:
    # åªå…è®¸ PDF / DOCXï¼Œâ‰¤50MB
    MAX_UPLOAD_MB = 50
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ ç®€å†ï¼ˆPDF æˆ– DOCXï¼‰",
        type=["pdf", "docx"],
        accept_multiple_files=False,
        help="å•æ–‡ä»¶ â‰¤ 50MBï¼›å¦‚æœæ˜¯æ‰«æä»¶ï¼Œè¯·åœ¨å·¦ä¾§å¼€å¯ OCRã€‚"
    )

    # å¤§å° & åç¼€æ ¡éªŒ
    if uploaded_file is not None:
        try:
            size_bytes = getattr(uploaded_file, "size", None)
            if size_bytes is None:
                size_bytes = len(uploaded_file.getbuffer())
        except Exception:
            size_bytes = None

        if size_bytes is not None and size_bytes > MAX_UPLOAD_MB * 1024 * 1024:
            mb = size_bytes / (1024 * 1024)
            st.error(f"æ–‡ä»¶è¿‡å¤§ï¼ˆ{mb:.1f} MBï¼‰ã€‚è¯·å‹ç¼©è‡³ {MAX_UPLOAD_MB}MB ä»¥å†…åå†ä¸Šä¼ ã€‚")
            st.stop()

        name = uploaded_file.name.lower()
        if not (name.endswith(".pdf") or name.endswith(".docx")):
            st.error("å½“å‰ç‰ˆæœ¬ä»…æ”¯æŒ PDF æˆ– DOCX æ–‡ä»¶ã€‚")
            st.stop()

with col_right:
    jd_text = st.text_area(
        "ç²˜è´´ç›®æ ‡èŒä½ JD æˆ–ä¼˜åŒ–æŒ‡ä»¤ï¼ˆå¯æ‰¹é‡ã€ç”¨åˆ†éš”ï¼‰",
        placeholder="ä¾‹å¦‚ï¼šActuarial graduate role at Deloitte. è¯·é‡ç‚¹çªå‡ºæ•°æ®åˆ†æä¸å»ºæ¨¡èƒ½åŠ›ï¼›Cover Letter æ›´æ­£å¼ã€‚",
        height=150
    )

st.info("ğŸ’¡ æç¤ºï¼šå¯åœ¨å·¦ä¾§è®¾ç½®â€œç²¾ä¿®ä¾§é‡/å¢å¼ºç‚¹â€ï¼›è‹¥ PDF ä¸ºæ‰«æä»¶ï¼Œå¯å¼€å¯ OCRã€‚", icon="ğŸ’¡")

# ä½¿ç”¨ form è®©æŒ‰é’®å§‹ç»ˆå¯è§
with st.form("gen_form", clear_on_submit=False):
    submitted = st.form_submit_button("ğŸš€ ä¸€é”®ç”Ÿæˆ", use_container_width=True)

# ============= ç”Ÿæˆå¤„ç† =============
if submitted:
    if not uploaded_file:
        st.warning("è¯·å…ˆä¸Šä¼ ç®€å†æ–‡ä»¶ï¼ˆPDF / DOCXï¼‰ã€‚")
    elif not OPENAI_API_KEY:
        st.error("æœªé…ç½® OPENAI_API_KEYï¼Œæ— æ³•è°ƒç”¨æ¨¡å‹ã€‚")
    else:
        try:
            with st.spinner("AI æ­£åœ¨åˆ†æå¹¶ä¼˜åŒ–ä¸­ï¼Œè¯·ç¨å€™â€¦"):
                resume_text, fmt = read_resume(uploaded_file, use_ocr=use_ocr)
                lang = detect_language(resume_text)
                st.session_state.detected_lang = lang
                st.session_state.last_file_format = fmt

                focus_directives = build_focus_instructions(focus_tags, custom_points, lang)

                optimized = llm_optimize_resume(resume_text, jd_text, lang, focus_directives)
                st.session_state.optimized_resume = optimized

                if need_cl:
                    cl = llm_cover_letter(resume_text, jd_text, lang, focus_directives)
                    st.session_state.cover_letter = cl
                else:
                    st.session_state.cover_letter = None

            lang_badge = "ä¸­æ–‡" if st.session_state.detected_lang == "zh" else "English"
            st.success(f"å·²å®Œæˆï¼æ£€æµ‹è¯­è¨€ï¼š**{lang_badge}**ï¼Œæ¥æºï¼š**{st.session_state.last_file_format}**ã€‚è¯·åœ¨ä¸‹æ–¹æŸ¥çœ‹ä¸ä¸‹è½½ã€‚")

            # å¦‚æœ OCR å¼€å¯ä½†ä¾èµ–ç¼ºå¤±ï¼Œç»™å‹å¥½æç¤º
            if use_ocr and st.session_state.last_file_format == "PDF" and not _safe_import_ocr()[0]:
                st.warning("å·²å°è¯• OCRï¼Œä½†è¿è¡Œç¯å¢ƒå¯èƒ½ç¼ºå°‘ä¾èµ–ï¼ˆTesseract/Popplerï¼‰ã€‚è¯·åœ¨æœ¬åœ°æˆ–è‡ªå»ºç¯å¢ƒå®‰è£…åå†è¯•ã€‚")

        except Exception as e:
            st.error(f"âŒ å‡ºé”™ï¼š{e}")

# ============= ç»“æœå±•ç¤º / ä¸‹è½½ï¼ˆä¸ä¼šå› ä¸‹è½½è€Œæ¸…ç©ºï¼‰ =============
if st.session_state.optimized_resume:
    st.subheader("âœ… ä¼˜åŒ–åçš„ç®€å†")
    st.text_area("Resume Preview", st.session_state.optimized_resume, height=360)
    st.download_button(
        "ğŸ“„ ä¸‹è½½ä¼˜åŒ–ç®€å†ï¼ˆWordï¼‰",
        data=to_docx_bytes(st.session_state.optimized_resume),
        file_name="Optimized_Resume.docx",
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        use_container_width=True
    )

if st.session_state.cover_letter:
    st.subheader("ğŸ“¬ æ±‚èŒä¿¡ï¼ˆCover Letterï¼‰")
    st.text_area("Cover Letter Preview", st.session_state.cover_letter, height=280)
    st.download_button(
        "ğŸ“„ ä¸‹è½½æ±‚èŒä¿¡ï¼ˆWordï¼‰",
        data=to_docx_bytes(st.session_state.cover_letter),
        file_name="Cover_Letter.docx",
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        use_container_width=True
    )

st.markdown("---")
st.caption("Â© 2025 AI Resume Optimizerï½œä»…ä¾›ä¸ªäººæ±‚èŒä½¿ç”¨ï¼Œç¦æ­¢å•†ç”¨ä¸çˆ¬å–ã€‚")