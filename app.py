import io
import os
from datetime import datetime

import streamlit as st
from openai import OpenAI
from langdetect import detect
import pdfplumber
from docx import Document

# =========================================================
# 1. åŸºç¡€é…ç½® & å®‰å…¨åœ°åŠ è½½ analyticsï¼ˆå¯é€‰ï¼‰
# =========================================================

st.set_page_config(
    page_title="AI æ™ºèƒ½ç®€å†ä¼˜åŒ–",
    page_icon="ğŸ§ ",
    layout="wide",
)

# éšè—å³ä¸Šè§’çš„ â€œView code / Rerunâ€ èœå•ï¼Œé¿å…æ™®é€šç”¨æˆ·çœ‹åˆ°æºç 
HIDE_STREAMLIT_STYLE = """
    <style>
    [data-testid="stToolbar"] { visibility: hidden; height: 0; position: fixed; }
    [data-testid="stDecoration"] { visibility: hidden; height: 0; }
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    </style>
"""
st.markdown(HIDE_STREAMLIT_STYLE, unsafe_allow_html=True)

# ---- OpenAI å®¢æˆ·ç«¯ ----
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
MODEL_NAME = os.getenv("MODEL_NAME", "gpt-4o-mini")

if not OPENAI_API_KEY:
    st.error("æœªé…ç½® OPENAI_API_KEYï¼Œè¯·åœ¨ Streamlit â†’ Settings â†’ Secrets ä¸­æ·»åŠ ã€‚")
client = OpenAI()


# ---- å®‰å…¨åŠ è½½ analyticsï¼ˆGoogle Sheetï¼‰ ----
try:
    import analytics  # ä½ è‡ªå·±çš„ analytics.py

    ANALYTICS_AVAILABLE = True
except Exception:
    analytics = None
    ANALYTICS_AVAILABLE = False


def safe_log_event(event_type: str, data: dict):
    """æ‰€æœ‰åŸ‹ç‚¹éƒ½é€šè¿‡è¿™é‡Œè°ƒç”¨ï¼Œé¿å…å½±å“ä¸»æµç¨‹"""
    if not ANALYTICS_AVAILABLE:
        return
    try:
        analytics.log_event(event_type, data)
    except Exception:
        # ä¸åœ¨ UI ä¸­æ‰“æ‰°ç”¨æˆ·ï¼Œåªæ˜¯é™é»˜å¤±è´¥
        pass


# =========================================================
# 2. å·¥å…·å‡½æ•°ï¼šè¯»å–ç®€å† & ç”Ÿæˆ DOCX
# =========================================================

def read_docx(file_bytes: bytes) -> str:
    buffer = io.BytesIO(file_bytes)
    doc = Document(buffer)
    texts = []
    for para in doc.paragraphs:
        if para.text.strip():
            texts.append(para.text.strip())
    return "\n".join(texts)


def read_pdf(file_bytes: bytes) -> str:
    buffer = io.BytesIO(file_bytes)
    texts = []
    with pdfplumber.open(buffer) as pdf:
        for page in pdf.pages:
            try:
                t = page.extract_text() or ""
            except Exception:
                t = ""
            if t.strip():
                texts.append(t.strip())
    return "\n\n".join(texts)


def extract_resume_text(uploaded_file, enable_ocr: bool) -> str:
    """æ ¹æ®æ–‡ä»¶ç±»å‹æå–æ–‡æœ¬ï¼›OCR ç›®å‰åªç»™æç¤ºï¼Œä¸åšçœŸæ­£è¯†åˆ«"""
    suffix = (uploaded_file.name or "").lower()

    file_bytes = uploaded_file.read()
    # è¯»å®Œè¦å¤ä½ï¼Œä¸ç„¶åé¢å†è¯»ä¼šæ˜¯ç©º
    uploaded_file.seek(0)

    if suffix.endswith(".docx"):
        return read_docx(file_bytes)
    elif suffix.endswith(".pdf"):
        text = read_pdf(file_bytes)
        if not text.strip() and enable_ocr:
            st.warning("æ£€æµ‹åˆ° PDF å¯èƒ½æ˜¯æ‰«æä»¶ï¼Œç›®å‰ç‰ˆæœ¬å°šæœªæ¥å…¥ OCR å¼•æ“ï¼Œå…ˆæŒ‰ç©ºæ–‡æœ¬å¤„ç†ã€‚")
        return text
    else:
        st.error("ç›®å‰ä»…æ”¯æŒ PDF æˆ– DOCX æ–‡ä»¶ã€‚")
        return ""


def create_docx(content: str) -> bytes:
    """å°†çº¯æ–‡æœ¬å†™å…¥ DOCXï¼Œå¹¶ä»¥ bytes å½¢å¼è¿”å›ç”¨äºä¸‹è½½"""
    doc = Document()
    for line in content.splitlines():
        doc.add_paragraph(line)
    buffer = io.BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer.getvalue()


# =========================================================
# 3. Prompt æ„å»º & è°ƒ OpenAI
# =========================================================

def detect_language(text: str) -> str:
    try:
        lang = detect(text[:1000])
    except Exception:
        lang = "en"
    if lang.startswith("zh"):
        return "zh"
    return "en"


def build_prompt(
    resume_text: str,
    jd_text: str,
    focus_tags: list,
    extra_points: str,
    need_cover_letter: bool,
    lang: str,
) -> str:
    lang_label = "ä¸­æ–‡" if lang == "zh" else "è‹±æ–‡"

    focus_str = "ã€".join(focus_tags) if focus_tags else "é€šç”¨æ±‚èŒèƒ½åŠ›"
    extra_str = extra_points.strip() or "æŒ‰ç…§ç›®æ ‡å²—ä½å’Œç®€å†å†…å®¹è¿›è¡Œä¸“ä¸šä¼˜åŒ–ã€‚"

    cover_tip = (
        "åŒæ—¶ç”Ÿæˆä¸€å°åŒ¹é…è¯¥å²—ä½çš„æ±‚èŒä¿¡ï¼ˆCover Letterï¼‰ã€‚"
        if need_cover_letter
        else "ä¸éœ€è¦ç”Ÿæˆæ±‚èŒä¿¡ï¼Œåªä¼˜åŒ–ç®€å†æœ¬èº«ã€‚"
    )

    jd_part = jd_text.strip() or "æœªæä¾›è¯¦ç»† JDï¼Œåªæ ¹æ®ç®€å†å†…å®¹åšé€šç”¨ä¼˜åŒ–ã€‚"

    prompt = f"""
ä½ æ˜¯ä¸€åä¸“ä¸šçš„äººæ‰æ‹›è˜ä¸èŒä¸šå‘å±•é¡¾é—®ï¼Œæ“…é•¿ä¸º{lang_label}ç®€å†åšæ·±åº¦ä¼˜åŒ–ã€‚
è¯·æ ¹æ®ã€å€™é€‰äººåŸå§‹ç®€å†ã€‘å’Œã€ç›®æ ‡å²—ä½/ä¼˜åŒ–æŒ‡ä»¤ã€‘ï¼Œè¾“å‡ºï¼š

1. ä¸€ä»½ç»“æ„æ¸…æ™°ã€å¯ç›´æ¥æŠ•é€’çš„{lang_label}ç®€å†æ–‡æœ¬ï¼›
2. {cover_tip}
3. ä¿æŒå†…å®¹çœŸå®æ€§ï¼Œä¸è™šæ„ç»å†æˆ–æŠ€èƒ½ï¼›
4. ä¿ç•™å°½å¯èƒ½å¤šçš„å…³é”®ç»†èŠ‚ï¼Œä½†å…è®¸ä¼˜åŒ–è¡¨è¿°æ–¹å¼ï¼›
5. å°½é‡é‡åŒ–æˆç»©ï¼ˆä¾‹å¦‚ç”¨ç™¾åˆ†æ¯”ã€é‡‘é¢ã€è§„æ¨¡ç­‰ï¼‰ï¼›
6. ä¸¥æ ¼é¿å…ä»»ä½•æ°´å°ã€é˜…è¯»è¯´æ˜æˆ–â€œç”± AI ç”Ÿæˆâ€çš„å­—æ ·ï¼Œåªè¾“å‡ºçœŸå®å¯ç”¨å†…å®¹ï¼›
7. è¾“å‡ºè¯­è¨€å¿…é¡»ä¸ã€å€™é€‰äººåŸå§‹ç®€å†ã€‘ä¸€è‡´ï¼ˆæœ¬æ¬¡åº”ä¸ºï¼š{lang_label}ï¼‰ã€‚

æœ¬æ¬¡ç²¾ä¿®é‡ç‚¹åŒ…æ‹¬ï¼ˆä½†ä¸é™äºï¼‰ï¼š{focus_str}ã€‚
ä½ è¿˜éœ€è¦ç‰¹åˆ«æ³¨æ„ï¼š{extra_str}

è¯·æŒ‰ç…§ä¸‹é¢çš„è¾“å‡ºæ ¼å¼ç»„ç»‡ç»“æœï¼ˆæ³¨æ„åˆ†éš”æ ‡è®°ï¼‰ï¼š

==== ä¼˜åŒ–åç®€å† START ====
ï¼ˆè¿™é‡Œæ˜¯å¯ä»¥ç›´æ¥å¤åˆ¶åˆ° Word é‡Œçš„å®Œæ•´{lang_label}ç®€å†ï¼‰
==== ä¼˜åŒ–åç®€å† END ====

==== æ±‚èŒä¿¡ START ====
ï¼ˆå¦‚æœéœ€è¦æ±‚èŒä¿¡ï¼Œåˆ™è¾“å‡ºå®Œæ•´{lang_label}æ±‚èŒä¿¡ï¼›å¦‚æœç”¨æˆ·ä¸éœ€è¦æ±‚èŒä¿¡ï¼Œè¯·ç•™ç©ºï¼‰
==== æ±‚èŒä¿¡ END ====

-----------------------
ã€å€™é€‰äººåŸå§‹ç®€å†ã€‘
{resume_text}

-----------------------
ã€ç›®æ ‡å²—ä½ / ä¼˜åŒ–æŒ‡ä»¤ã€‘
{jd_part}
"""
    return prompt


def call_openai(prompt: str) -> str:
    response = client.responses.create(
        model=MODEL_NAME,
        input=prompt,
    )
    # æ–°ç‰ˆ Responses APIï¼šå–ç¬¬ä¸€æ®µæ–‡æœ¬
    try:
        return response.output[0].content[0].text
    except Exception:
        # å…œåº•ï¼šç›´æ¥è½¬æˆå­—ç¬¦ä¸²
        return str(response)


def parse_model_output(raw: str):
    """æ ¹æ®çº¦å®šçš„åˆ†éš”ç¬¦åˆ‡åˆ†å‡ºç®€å† & æ±‚èŒä¿¡"""
    resume = ""
    cover = ""

    if "==== ä¼˜åŒ–åç®€å† START ====" in raw:
        try:
            part = raw.split("==== ä¼˜åŒ–åç®€å† START ====")[1]
            part = part.split("==== ä¼˜åŒ–åç®€å† END ====")[0]
            resume = part.strip()
        except Exception:
            resume = raw.strip()
    else:
        resume = raw.strip()

    if "==== æ±‚èŒä¿¡ START ====" in raw:
        try:
            part = raw.split("==== æ±‚èŒä¿¡ START ====")[1]
            part = part.split("==== æ±‚èŒä¿¡ END ====")[0]
            cover = part.strip()
        except Exception:
            cover = ""

    return resume, cover


# =========================================================
# 4. é¡µé¢ UI
# =========================================================

# ---- å·¦ä¾§è®¾ç½®æ  ----
with st.sidebar:
    st.title("è®¾ç½®")

    st.caption("ï¼ˆå·¦ä¾§é€‰é¡¹ä»…å½±å“ç”Ÿæˆçš„å¼ºè°ƒæ–¹å‘ï¼‰")

    focus_options = [
        "ä¸šåŠ¡å½±å“",
        "æ²Ÿé€šåä½œ",
        "é¢†å¯¼åŠ›/Ownership",
        "é¡¹ç›®ç®¡ç†",
        "æ•°æ®é©±åŠ¨ã€å¯é‡åŒ–",
        "å…³é”®å­—å¥‘åˆåº¦ï¼ˆATS å‹å¥½ï¼‰",
    ]
    focus_tags = st.multiselect(
        "ç²¾ä¿®ä¾§é‡ï¼ˆå¯å¤šé€‰ï¼‰",
        options=focus_options,
        default=["ä¸šåŠ¡å½±å“"],
    )

    extra_points = st.text_area(
        "å¢å¼ºç‚¹ï¼ˆå¯è‡ªå®šä¹‰ï¼‰",
        value="ä¾‹å¦‚ï¼šå¼ºè°ƒæ•°æ®åˆ†æ/é‡åŒ–æˆæœï¼›çªå‡ºä¸ç›®æ ‡å²—ä½çš„åŒ¹é…ï¼›æˆ–å†™ä½œé£æ ¼è¦æ±‚ç­‰â€¦",
        height=120,
    )

    need_cover_letter = st.checkbox("âœ‰ï¸ ç”Ÿæˆæ±‚èŒä¿¡ï¼ˆCover Letterï¼‰", value=True)
    enable_ocr = st.checkbox("ğŸ” å¯ç”¨ OCRï¼ˆæ‰«æ PDFï¼‰", value=False)

    st.markdown("---")
    st.caption("ä»…ä¾›ä¸ªäººæ±‚èŒä½¿ç”¨ï¼Œç¦æ­¢å•†ç”¨ä¸çˆ¬å–ã€‚")

# ---- é¡µé¢æ ‡é¢˜ ----
st.markdown("## ğŸ§  AI æ™ºèƒ½ç®€å†ä¼˜åŒ–")

col_left, col_right = st.columns(2, gap="large")

with col_left:
    st.subheader("ä¸Šä¼ ç®€å†ï¼ˆPDF æˆ– DOCXï¼‰")
    uploaded_file = st.file_uploader(
        "", type=["pdf", "docx"], label_visibility="collapsed"
    )
    st.caption("æ”¯æŒ PDF / DOCXï¼Œå•æ–‡ä»¶ â‰¤ 50MBï¼›æ‰«æä»¶å¯å¯ç”¨ OCRã€‚")

with col_right:
    st.subheader("ç²˜è´´ç›®æ ‡èŒä½ JD æˆ–ä¼˜åŒ–æŒ‡ä»¤ï¼ˆå¯æ‰¹é‡ã€ç”¨åˆ†éš”ï¼‰")
    jd_text = st.text_area(
        "",
        placeholder=(
            "ä¾‹å¦‚ï¼šActuarial graduate role at Deloitteã€‚"
            "å¯ä»¥ç›´æ¥å†™ JDï¼Œä¹Ÿå¯ä»¥å†™ä¼˜åŒ–æŒ‡ä»¤ï¼Œä¾‹å¦‚ï¼š"
            "â€˜è¯·é‡ç‚¹çªå‡ºæ•°æ®åˆ†æä¸å»ºæ¨¡èƒ½åŠ›ï¼›Cover Letter è¦æ›´æ­£å¼â€™ã€‚"
        ),
        height=180,
        label_visibility="collapsed",
    )

st.info("ğŸ’¡ æç¤ºï¼šå¯åœ¨å·¦ä¾§è®¾ç½®â€œç²¾ä¿®ä¾§é‡/å¢å¼ºç‚¹â€ï¼›è‹¥ PDF ä¸ºæ‰«æä»¶ï¼Œå¯å¼€å¯ OCRã€‚")

# ---- é¦–æ¬¡æ‰“å¼€é¡µé¢çš„åŸ‹ç‚¹ ----
safe_log_event(
    "page_view",
    {
        "ts": datetime.utcnow().isoformat(),
        "has_file": bool(uploaded_file),
    },
)

# =========================================================
# 5. ä¸»æŒ‰é’®ï¼šä¸€é”®ç”Ÿæˆ
# =========================================================

generate_btn = st.button("ğŸš€ ä¸€é”®ç”Ÿæˆ", use_container_width=True)

if generate_btn:
    if not uploaded_file:
        st.error("è¯·å…ˆä¸Šä¼ ç®€å†æ–‡ä»¶ï¼ˆPDF æˆ– DOCXï¼‰ã€‚")
        st.stop()

    if uploaded_file.size and uploaded_file.size > 50 * 1024 * 1024:
        st.error("æ–‡ä»¶è¶…è¿‡ 50MBï¼Œè¯·å‹ç¼©åé‡æ–°ä¸Šä¼ ã€‚")
        st.stop()

    with st.spinner("æ­£åœ¨è¯»å–ç®€å†å¹¶è°ƒç”¨ AI ä¼˜åŒ–ï¼Œè¯·ç¨å€™â€¦"):
        resume_text = extract_resume_text(uploaded_file, enable_ocr)

        if not resume_text.strip():
            st.error("æœªèƒ½ä»ç®€å†ä¸­æå–æ–‡æœ¬ï¼Œè¯·ç¡®è®¤æ–‡ä»¶æ˜¯å¦ä¸ºå¯å¤åˆ¶æ–‡æœ¬ã€‚")
            st.stop()

        lang = detect_language(resume_text)

        prompt = build_prompt(
            resume_text=resume_text,
            jd_text=jd_text,
            focus_tags=focus_tags,
            extra_points=extra_points,
            need_cover_letter=need_cover_letter,
            lang=lang,
        )

        raw_output = call_openai(prompt)
        optimized_resume, cover_letter_text = parse_model_output(raw_output)

    # ===== ä¸‹è½½åŒº =====
    st.success("ç”Ÿæˆå®Œæˆï¼Œä½ å¯ä»¥ä¸‹è½½ä¼˜åŒ–åçš„ç®€å†ï¼ˆä»¥åŠå¯é€‰çš„æ±‚èŒä¿¡ï¼‰ã€‚")

    resume_docx_bytes = create_docx(optimized_resume)
    resume_filename = "Optimized_Resume.docx"
    st.download_button(
        "â¬‡ï¸ ä¸‹è½½ä¼˜åŒ–ç®€å†ï¼ˆDOCXï¼‰",
        data=resume_docx_bytes,
        file_name=resume_filename,
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    )

    if need_cover_letter and cover_letter_text.strip():
        cover_docx_bytes = create_docx(cover_letter_text)
        cover_filename = "Cover_Letter.docx"
        st.download_button(
            "â¬‡ï¸ ä¸‹è½½æ±‚èŒä¿¡ï¼ˆDOCXï¼‰",
            data=cover_docx_bytes,
            file_name=cover_filename,
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        )
    elif need_cover_letter:
        st.warning("æœ¬æ¬¡æ¨¡å‹è¾“å‡ºä¸­æœªè¯†åˆ«åˆ°æœ‰æ•ˆæ±‚èŒä¿¡å†…å®¹ï¼Œè¯·æ£€æŸ¥æç¤ºè¯æˆ–é‡æ–°ç”Ÿæˆã€‚")

    # è®°å½•ç”Ÿæˆäº‹ä»¶
    safe_log_event(
        "generate",
        {
            "ts": datetime.utcnow().isoformat(),
            "filename": uploaded_file.name,
            "filesize": uploaded_file.size,
            "lang": lang,
            "has_jd": bool(jd_text.strip()),
            "need_cover_letter": need_cover_letter,
        },
    )

# =========================================================
# 6. ç”¨æˆ·åé¦ˆå…¥å£
# =========================================================

st.markdown("---")
feedback = st.text_area(
    "ğŸ’¬ æäº¤åé¦ˆ / åŠŸèƒ½å»ºè®®ï¼ˆå¯é€‰ï¼‰",
    placeholder="ä¾‹å¦‚ï¼šå“ªé‡Œç”¨å¾—ä¸é¡ºæ‰‹ï¼Ÿå¸Œæœ›å¢åŠ ä»€ä¹ˆåŠŸèƒ½ï¼Ÿæˆ–è€…é‡åˆ°äº†ä»€ä¹ˆé”™è¯¯ï¼Ÿ",
    height=100,
)

if st.button("ğŸ“¨ æäº¤åé¦ˆ", use_container_width=False):
    if not feedback.strip():
        st.warning("è¯·å…ˆå¡«å†™ä¸€äº›åé¦ˆå†…å®¹ï¼Œå†ç‚¹å‡»æäº¤ã€‚")
    else:
        safe_log_event(
            "user_feedback",
            {
                "ts": datetime.utcnow().isoformat(),
                "feedback": feedback.strip(),
            },
        )
        st.success("è°¢è°¢ä½ çš„åé¦ˆï¼æˆ‘ä¼šæ ¹æ®è¿™äº›å»ºè®®æŒç»­ä¼˜åŒ–äº§å“ã€‚")