# app_user_refined.py â€” æ­£å¼ç‰ˆå¤–è§‚ï¼ˆå•ä¸€æ¨¡å¼ï¼›æ±‚èŒä¿¡è¯­è¨€è‡ªåŠ¨ï¼›æ—  ATS æ£€æµ‹/æ— å¤šç‰ˆæœ¬/æ— æ”¯ä»˜ï¼‰
# ä¾èµ–ï¼šstreamlit pdfplumber python-docx python-dotenv reportlab pdf2image pytesseract pillow openai

import os, io, re, json
from typing import List, Dict, Tuple
import streamlit as st
import pdfplumber
from dotenv import load_dotenv
from docx import Document

# ---------- å¯é€‰ PDF å¯¼å‡º ----------
try:
    from reportlab.pdfgen import canvas
    from reportlab.lib.pagesizes import A4
    from reportlab.lib.units import mm
    HAS_PDF = True
except Exception:
    HAS_PDF = False

# ---------- å¯é€‰ OCR ----------
_HAS_OCR = True
try:
    from pdf2image import convert_from_bytes
    import pytesseract
    from PIL import Image  # noqa: F401
except Exception:
    _HAS_OCR = False

# ---------- OpenAI ----------
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
client = None
if OPENAI_API_KEY:
    try:
        from openai import OpenAI
        client = OpenAI(api_key=OPENAI_API_KEY)
    except Exception:
        client = None

# ======================================================
# å·¥å…·å‡½æ•°
# ======================================================
def to_plain_text(x) -> str:
    if isinstance(x, str): return x
    try:
        return json.dumps(x, ensure_ascii=False, indent=2)
    except Exception:
        return str(x)

def extract_text_from_pdf_bytes(data: bytes, enable_ocr=True) -> Tuple[str, bool, int, str]:
    text, used_ocr, pages_count, lang_hint = "", False, 0, ""
    try:
        with pdfplumber.open(io.BytesIO(data)) as pdf:
            pages = []
            for p in pdf.pages:
                pages_count += 1
                pages.append(p.extract_text() or "")
            text = "\n".join(pages).strip()
    except Exception:
        text = ""
    if enable_ocr and len(text) < 80:
        if not _HAS_OCR:
            return text, False, pages_count, ""
        try:
            images = convert_from_bytes(data, dpi=300)
            ocr_out = [pytesseract.image_to_string(img, lang="chi_sim+eng") for img in images]
            text = "\n".join(ocr_out).strip()
            used_ocr = True
            pages_count = len(images) if pages_count == 0 else pages_count
            lang_hint = "chi_sim+eng"
            return text, used_ocr, pages_count, lang_hint
        except Exception:
            pass
    return text, used_ocr, pages_count, lang_hint

def extract_text_from_docx(file) -> str:
    doc = Document(file)
    return "\n".join([p.text for p in doc.paragraphs]).strip()

def make_docx_from_text(text: str) -> bytes:
    doc = Document()
    for line in to_plain_text(text).splitlines():
        doc.add_paragraph(line)
    bio = io.BytesIO(); doc.save(bio); return bio.getvalue()

def make_pdf_from_text(text: str) -> bytes:
    if not HAS_PDF:
        raise RuntimeError("ç¼ºå°‘ reportlabï¼špip install reportlab")
    bio = io.BytesIO(); c = canvas.Canvas(bio, pagesize=A4)
    width, height = A4; margin = 15*mm; y = height - margin
    c.setFont("Helvetica", 10)
    for line in to_plain_text(text).splitlines():
        if y < margin:
            c.showPage(); c.setFont("Helvetica", 10); y = height - margin
        c.drawString(margin, y, line[:110]); y -= 6*mm
    c.showPage(); c.save(); return bio.getvalue()

def robust_json_loads(s: str):
    try:
        return json.loads(s)
    except Exception:
        pass
    s2 = s.strip()
    if s2.startswith("```"):
        s2 = re.sub(r"^```[a-zA-Z]*", "", s2).strip()
        if s2.endswith("```"):
            s2 = s2[:-3]
    try:
        return json.loads(s2)
    except Exception:
        pass
    start, end = s.find("{"), s.rfind("}")
    if start != -1 and end != -1 and end > start:
        return json.loads(s[start:end+1])
    raise ValueError("æ— æ³•ä»æ¨¡å‹è¾“å‡ºä¸­è§£ææœ‰æ•ˆ JSONã€‚")

def infer_title_from_filename(name: str) -> str:
    if not name: return "Curriculum Vitae"
    base = re.sub(r"\.(pdf|docx)$", "", name, flags=re.I)
    base = re.sub(r"[_-]+", " ", base).strip()
    base = re.sub(r"(?i)optimized\s*resume", "", base).strip()
    if not base: return "Curriculum Vitae"
    return f"{base} â€“ CV"

# ---------- ç®€å†è¯­è¨€æ£€æµ‹ï¼ˆå†³å®šæ±‚èŒä¿¡è¯­è¨€ï¼‰ ----------
def detect_resume_language(text: str) -> str:
    """è¿”å› 'en' or 'zh'ï¼ˆå¯å‘å¼ï¼‰ï¼šä¸­æ–‡æ±‰å­—æ•° vs è‹±æ–‡å­—æ¯æ•°ï¼›é»˜è®¤è‹±æ–‡"""
    chinese = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
    english = sum(1 for c in text if c.isascii() and c.isalpha())
    return "zh" if chinese > english else "en"

# ======================================================
# OpenAI è°ƒç”¨
# ======================================================
BASE_TASK = """
ã€åŸå§‹ç®€å†ã€‘
{resume_text}

ã€ç›®æ ‡èŒä½JDã€‘
{jd_text}

ä»»åŠ¡ï¼š
1) æŠ½å–3-8æ¡ä»£è¡¨æ€§çš„ before_bulletsï¼›
2) äº§å‡ºä¸JDå¯¹é½çš„ after_bulletsï¼ˆåŠ¨è¯å¼€å¤´ã€å¯é‡åŒ–ï¼‰ï¼›
3) ç”Ÿæˆ optimized_resumeï¼ˆæŒ‰æ¸…æ™°åˆ†èŠ‚ï¼Œå•åˆ—ã€æ— è¡¨æ ¼/å›¾ç‰‡ï¼Œä¾¿äºæœºå™¨è§£æï¼‰ï¼›
4) {cover_directive}
5) ä»…ç”Ÿæˆ 1 ä¸ªä¸»ç‰ˆæœ¬ã€‚

è¿”å›ä¸¥æ ¼ JSONï¼š
{{
  "optimized_resume": "â€¦",
  "match_score": 0,
  "missing_keywords": [],
  "suggested_bullets": [],
  "notes": "",
  "before_bullets": [],
  "after_bullets": [],
  "cover_letter": ""
}}
"""

def build_prompt(resume_text: str, jd_text: str, refine: List[str], emphasis: str,
                 want_cover: bool, cl_lang: str) -> str:
    refine_str = "ã€".join(refine) if refine else "å‡è¡¡"
    # æ±‚èŒä¿¡è¯­è¨€æŒ‡ä»¤
    if want_cover:
        if cl_lang == "zh":
            cover_directive = "ç”Ÿæˆä¸­æ–‡æ±‚èŒä¿¡ï¼ˆCover Letterï¼‰ï¼Œâ‰¤ 1 é¡µï¼Œæ­£å¼èŒåœºè¯­æ°”ã€‚"
        else:
            cover_directive = "Generate an English cover letter (â‰¤ 1 page, professional tone)."
    else:
        cover_directive = "æ— éœ€ç”Ÿæˆæ±‚èŒä¿¡ï¼ˆCover Letterï¼‰ã€‚"

    head = f"""ä½ æ˜¯ä¸€åèµ„æ·±èŒä¸šé¡¾é—®ã€‚
è¯·æ ¹æ®ä»¥ä¸‹ç®€å†ä¸èŒä½æè¿°è¿›è¡Œä¸“ä¸šä¼˜åŒ–ã€‚
ç²¾ä¿®ä¾§é‡ï¼š{refine_str}ï¼›å¼ºè°ƒç‚¹ï¼š{emphasis or 'æ•°æ®é©±åŠ¨ã€å¯é‡åŒ–ã€å…³é”®è¯å¥‘åˆ'}ã€‚

è¯­è¨€è¦æ±‚ï¼š
- optimized_resumeï¼šæ²¿ç”¨åŸç®€å†è¯­è¨€ï¼ˆä¸­æ–‡â†’ä¸­æ–‡ï¼Œè‹±æ–‡â†’è‹±æ–‡ï¼‰ã€‚
- cover_letterï¼šä¸¥æ ¼æŒ‰ç…§ä¸Šé¢çš„è¯­è¨€æŒ‡ä»¤ï¼ˆä¸ç®€å†è¯­è¨€ä¸€è‡´ï¼‰ã€‚"""
    return head + BASE_TASK.format(
        resume_text=resume_text,
        jd_text=jd_text,
        cover_directive=cover_directive
    )

def call_openai_json(prompt: str) -> Dict:
    if client is None:
        return {
            "optimized_resume": "Demo mode: è¯·é…ç½® OPENAI_API_KEYã€‚",
            "match_score": 0, "missing_keywords": [], "suggested_bullets": [],
            "notes": "æœªé…ç½® OPENAI_API_KEYã€‚", "before_bullets": [], "after_bullets": [],
            "cover_letter": ""
        }
    # æ­£å¼å¤–è§‚ç‰ˆä½¿ç”¨è½»é‡æ¨¡å‹ï¼Œå“åº”æ›´å¿«ï¼›å¦‚éœ€æ›´å¼ºå¯åˆ‡æ¢ gpt-4o
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        temperature=0.2,
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": "You are an expert resume optimizer. Respond ONLY JSON."},
            {"role": "user", "content": prompt}
        ]
    )
    raw = resp.choices[0].message.content
    try:
        return robust_json_loads(raw)
    except Exception:
        return {"optimized_resume": raw, "match_score": 0, "missing_keywords": [],
                "suggested_bullets": [], "notes": "", "cover_letter": ""}

# ======================================================
# UI
# ======================================================
st.set_page_config(page_title="AI æ™ºèƒ½ç®€å†ä¼˜åŒ–", page_icon="ğŸ§©", layout="wide")
st.title("ğŸ§© AI æ™ºèƒ½ç®€å†ä¼˜åŒ–")
st.caption("è®©ä½ çš„ç®€å†æ›´ç¬¦åˆ HR ä¸ç®—æ³•çš„è¯­è¨€ã€‚å¯é€‰è‡ªåŠ¨ç”Ÿæˆæ±‚èŒä¿¡ï¼ˆCover Letterï¼‰ã€‚")

# session state
if "results" not in st.session_state: st.session_state.results = []
if "params" not in st.session_state: st.session_state.params = {}
if "export_title" not in st.session_state: st.session_state.export_title = ""
if "resume_lang" not in st.session_state: st.session_state.resume_lang = "en"

# Sidebarï¼ˆå•ä¸€æ¨¡å¼ï¼‰
with st.sidebar:
    st.header("è®¾ç½®")
    st.caption("è¯·é€‰æ‹©ä¼˜åŒ–å‚æ•°ï¼š")
    tone = st.selectbox("è¯­æ°”", ["ä¸“ä¸š", "è‡ªä¿¡", "ç»“æœå¯¼å‘", "è°¦é€Š"], index=0)
    refine = st.multiselect("ç²¾ä¿®ä¾§é‡", ["æŠ€æœ¯æ·±åº¦", "ä¸šåŠ¡å½±å“", "é¢†å¯¼åŠ›", "æ²Ÿé€šåä½œ"], default=["ä¸šåŠ¡å½±å“"])
    emphasis = st.text_input("å¼ºè°ƒç‚¹", value="æ•°æ®é©±åŠ¨ã€å¯é‡åŒ–ã€å…³é”®è¯å¥‘åˆ")
    want_cover = st.checkbox("ç”Ÿæˆ æ±‚èŒä¿¡ï¼ˆCover Letterï¼Œè‡ªåŠ¨éšç®€å†è¯­è¨€ï¼‰", value=True)
    st.divider()
    enable_ocr = st.checkbox("å¯ç”¨ OCRï¼ˆæ‰«æPDFï¼‰", value=True)

left, right = st.columns([1, 1])
with left:
    uploaded = st.file_uploader("ä¸Šä¼ ç®€å†ï¼ˆPDF æˆ– DOCXï¼‰", type=["pdf", "docx"])
with right:
    jd_text = st.text_area("ç²˜è´´ç›®æ ‡èŒä½ JDï¼ˆå¯æ‰¹é‡ï¼Œ--- åˆ†éš”ï¼‰", height=200)

run = st.button("ğŸš€ ä¸€é”®ç”Ÿæˆ", type="primary", use_container_width=True)

def split_jd_blocks(text: str):
    if not text.strip(): return []
    return [b.strip() for b in text.split("\n---\n") if b.strip()]

def split_and_run(resume_text: str, jd_text: str, cl_lang: str):
    blocks = split_jd_blocks(jd_text) or [jd_text.strip()]
    results = []
    for idx, jd in enumerate(blocks, start=1):
        prompt = build_prompt(resume_text, jd, refine=refine, emphasis=emphasis,
                              want_cover=want_cover, cl_lang=cl_lang)
        data = call_openai_json(prompt)
        data["_jd_idx"] = idx
        data["_jd_excerpt"] = (jd[:120] + "â€¦") if len(jd) > 120 else jd
        results.append(data)
    return results

if run:
    if not uploaded or not jd_text.strip():
        st.error("è¯·ä¸Šä¼ ç®€å†å¹¶ç²˜è´´ JDã€‚")
    else:
        # æ–‡ä»¶åâ†’å¯¼å‡ºæ ‡é¢˜
        st.session_state.export_title = re.sub(r"[\\/]", "-", re.sub(r"\.(pdf|docx)$","",uploaded.name, flags=re.I)).strip() or "Curriculum Vitae"
        # è§£ææ–‡ä»¶
        if uploaded.name.lower().endswith(".pdf"):
            data = uploaded.getvalue()
            resume_text, used_ocr, pages, ocr_lang_used = extract_text_from_pdf_bytes(data, enable_ocr=enable_ocr)
        else:
            resume_text = extract_text_from_docx(uploaded); used_ocr, pages, ocr_lang_used = False, None, None

        if not resume_text.strip():
            st.error("æœªä»æ–‡ä»¶ä¸­æå–åˆ°æ–‡æœ¬ã€‚è‹¥ä¸ºæ‰«æPDFï¼Œè¯·å¯ç”¨ OCR å¹¶å®‰è£…ä¾èµ–ã€‚")
        else:
            # æ£€æµ‹ç®€å†è¯­è¨€ï¼ˆå†³å®šæ±‚èŒä¿¡è¯­è¨€ï¼‰
            cl_lang = detect_resume_language(resume_text)
            st.session_state.resume_lang = cl_lang
            st.session_state.results = split_and_run(resume_text, jd_text, cl_lang=cl_lang)
            st.session_state.params = {
                "tone": tone, "refine": refine, "emphasis": emphasis,
                "want_cover": want_cover, "ocr_used": used_ocr, "ocr_lang": ocr_lang_used,
                "resume_lang": cl_lang
            }

def current_result():
    if not st.session_state.results: return None, None
    lst = st.session_state.results
    if len(lst) == 1: return lst[0], f"JD#{lst[0]['_jd_idx']}"
    labels = [f"JD#{r['_jd_idx']} Â· {r['_jd_excerpt']}" for r in lst]
    sel = st.selectbox("é€‰æ‹©æŸ¥çœ‹çš„ JD ç»“æœï¼š", labels, index=0)
    return lst[labels.index(sel)], sel

# ---------- å±•ç¤º ----------
tabs = st.tabs(["â­ ä¼˜åŒ–åç®€å†", "âœ‰ï¸ æ±‚èŒä¿¡ï¼ˆCover Letterï¼‰", "ğŸ“¤ å¯¼å‡º"])

with tabs[0]:
    res, label = current_result()
    if not res:
        st.info("å…ˆä¸Šä¼ å¹¶ç”Ÿæˆã€‚")
    else:
        lang_badge = "ä¸­æ–‡" if st.session_state.get('resume_lang') == 'zh' else "English"
        ocr_status = "ON" if st.session_state.params.get('ocr_used') else "OFF"
        ocr_lang = st.session_state.params.get('ocr_lang')
        ocr_extra = f" ({ocr_lang})" if ocr_lang else ""
        st.markdown(f"**{label}** Â· ç®€å†è¯­è¨€ï¼š{lang_badge} Â· OCR: {ocr_status}{ocr_extra}")
        st.code(to_plain_text(res.get("optimized_resume","")), language="markdown")

with tabs[1]:
    res, _ = current_result()
    if not res:
        st.info("æš‚æ— ç»“æœã€‚")
    else:
        cl = (res.get("cover_letter","") or "").strip()
        if cl:
            st.code(to_plain_text(cl), language="markdown")
        else:
            st.info("æœªç”Ÿæˆæ±‚èŒä¿¡ï¼ˆCover Letterï¼‰ã€‚å¯åœ¨å·¦ä¾§å‹¾é€‰åé‡æ–°ç”Ÿæˆã€‚")

with tabs[2]:
    res, _ = current_result()
    if not res:
        st.info("æš‚æ— ç»“æœã€‚")
    else:
        export_title = (st.session_state.get('export_title') or 'Curriculum Vitae').strip()
        txt = (res.get("optimized_resume","") or "").strip()

        # ä»…å¯¼å‡ºï¼ˆæ—  ATS æ£€æµ‹ï¼‰
        try:
            st.download_button("â¬‡ï¸ ä¸‹è½½ DOCXï¼ˆä¸»ç‰ˆæœ¬ï¼‰", data=make_docx_from_text(txt),
                               file_name=f"{export_title}.docx",
                               mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                               use_container_width=True)
        except Exception as e:
            st.warning(f"DOCX å¯¼å‡ºå¤±è´¥ï¼š{e}")

        if HAS_PDF:
            try:
                st.download_button("â¬‡ï¸ ä¸‹è½½ PDFï¼ˆä¸»ç‰ˆæœ¬ï¼‰", data=make_pdf_from_text(txt),
                                   file_name=f"{export_title}.pdf",
                                   mime="application/pdf", use_container_width=True)
            except Exception as e:
                st.warning(f"PDF å¯¼å‡ºå¤±è´¥ï¼š{e}")
        else:
            st.info("éœ€è¦å®‰è£… reportlab æ‰èƒ½å¯¼å‡º PDFï¼špip install reportlab")

        cl = (res.get("cover_letter","") or "").strip()
        if cl:
            st.subheader("æ±‚èŒä¿¡ï¼ˆCover Letterï¼‰å¯¼å‡º")
            try:
                st.download_button("â¬‡ï¸ ä¸‹è½½ DOCXï¼ˆæ±‚èŒä¿¡ï¼‰", data=make_docx_from_text(cl),
                                   file_name=f"{export_title}_æ±‚èŒä¿¡(CoverLetter).docx",
                                   mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                                   use_container_width=True)
            except Exception as e:
                st.warning(f"COVER DOCX å¯¼å‡ºå¤±è´¥ï¼š{e}")
            if HAS_PDF:
                try:
                    st.download_button("â¬‡ï¸ ä¸‹è½½ PDFï¼ˆæ±‚èŒä¿¡ï¼‰", data=make_pdf_from_text(cl),
                                       file_name=f"{export_title}_æ±‚èŒä¿¡(CoverLetter).pdf",
                                       mime="application/pdf", use_container_width=True)
                except Exception as e:
                    st.warning(f"COVER PDF å¯¼å‡ºå¤±è´¥ï¼š{e}")